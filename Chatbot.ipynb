{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj6yqQtG8V01"
      },
      "source": [
        "## **Mounting Drive & Loading Spacy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzGoVk8zksfu",
        "outputId": "48865359-e820-42e2-d4af-898997c775e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#input save path of drive folder here:\n",
        "save_path = \"/content/gdrive/MyDrive/Colab Notebooks/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_494KU5tnL2G",
        "outputId": "307c9929-843f-43fe-b687-37808780e473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-md==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.6.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.5)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "!python -m spacy download en_core_web_md\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4d6kTKc-iOQ"
      },
      "source": [
        "## **Main Chatbot - Training Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_W8CZVaNl59x"
      },
      "outputs": [],
      "source": [
        "# # Load and preprocess training data\n",
        "# training_data = [\n",
        "#     # Greetings\n",
        "#     (\"Hello!\", \"greet\"),\n",
        "#     (\"Hi!\", \"greet\"),\n",
        "#     (\"Greetings!\", \"greet\"),\n",
        "#     (\"Salutations!\", \"greet\"),\n",
        "#     (\"Good to see you!\", \"greet\"),\n",
        "#     (\"Howdy!\", \"greet\"),\n",
        "#     (\"Hey there!\", \"greet\"),\n",
        "#     (\"What’s up?\", \"greet\"),\n",
        "#     (\"How are you doing?\", \"greet\"),\n",
        "#     (\"How’s it going?\", \"greet\"),\n",
        "#     (\"Nice to see you!\", \"greet\"),\n",
        "#     (\"Pleased to meet you!\", \"greet\"),\n",
        "#     (\"Yo!\", \"greet\"),\n",
        "#     (\"What's new?\", \"greet\"),\n",
        "#     (\"How have you been?\", \"greet\"),\n",
        "#     (\"It’s been a while!\", \"greet\"),\n",
        "#     (\"Long time no see!\", \"greet\"),\n",
        "#     (\"Welcome!\", \"greet\"),\n",
        "#     (\"Glad to see you!\", \"greet\"),\n",
        "#     (\"How's everything?\", \"greet\"),\n",
        "#     (\"How are things?\", \"greet\"),\n",
        "#     (\"Good day!\", \"greet\"),\n",
        "#     (\"Hiya!\", \"greet\"),\n",
        "#     (\"Nice to meet you!\", \"greet\"),\n",
        "#     (\"Good afternoon!\", \"greet\"),\n",
        "#     (\"Hello again!\", \"greet\"),\n",
        "#     (\"Look who it is!\", \"greet\"),\n",
        "#     (\"Look what came in!\", \"greet\"),\n",
        "#     (\"Welcome back!\", \"greet\"),\n",
        "#     (\"Heyyy!\", \"greet\"),\n",
        "#     (\"Sup?\", \"greet\"),\n",
        "#     (\"Whazzup?\", \"greet\"),\n",
        "#     (\"Greetings and salutations!\", \"greet\"),\n",
        "#     (\"How’s life?\", \"greet\"),\n",
        "#     (\"How’s your day?\", \"greet\"),\n",
        "#     (\"How’s your day going?\", \"greet\"),\n",
        "#     (\"Are you okay?\", \"greet\"),\n",
        "#     (\"It's nice to meet you!\", \"greet\"),\n",
        "#     (\"It's a pleasure to meet you!\", \"greet\"),\n",
        "#     (\"How's the family?\", \"greet\"),\n",
        "#     (\"Hey! Long time no see!\", \"greet\"),\n",
        "#     (\"Hi, how are you holding up?\", \"greet\"),\n",
        "#     (\"Hey, how's life treating you?\", \"greet\"),\n",
        "#     (\"Look at you!\", \"greet\"),\n",
        "#     (\"You alright?\", \"greet\"),\n",
        "#     (\"Hey, haven’t seen you in ages!\", \"greet\"),\n",
        "#     (\"Good to have you back!\", \"greet\"),\n",
        "#     (\"Ahoy!\", \"greet\"),\n",
        "#     (\"Cheers!\", \"greet\"),\n",
        "#     (\"How’s everything coming along?\", \"greet\"),\n",
        "#     (\"Helo!\", \"greet\"),\n",
        "#     (\"Hei!\", \"greet\"),\n",
        "#     (\"Hows it going?\", \"greet\"),\n",
        "#     (\"Sup?\", \"greet\"),\n",
        "#     (\"How ya doin'?\", \"greet\"),\n",
        "#     (\"Heyya!\", \"greet\"),\n",
        "#     (\"Wazzup?\", \"greet\"),\n",
        "#     (\"How r u?\", \"greet\"),\n",
        "#     (\"What’s crackin'?\", \"greet\"),\n",
        "#     (\"Howdy doody!\", \"greet\"),\n",
        "#     (\"Heylo!\", \"greet\"),\n",
        "#     (\"Greetins!\", \"greet\"),\n",
        "#     (\"Salutashuns!\", \"greet\"),\n",
        "#     (\"Good to c u!\", \"greet\"),\n",
        "#     (\"Howz it goin?\", \"greet\"),\n",
        "#     (\"Hey ther!\", \"greet\"),\n",
        "#     (\"Whatsup?\", \"greet\"),\n",
        "#     (\"Howz life?\", \"greet\"),\n",
        "#     (\"How u doin?\", \"greet\"),\n",
        "#     (\"Howz everything?\", \"greet\"),\n",
        "#     (\"Howz it goin?\", \"greet\"),\n",
        "#     (\"Howz things?\", \"greet\"),\n",
        "#     (\"Plezed to meet u!\", \"greet\"),\n",
        "#     (\"Nise to see u!\", \"greet\"),\n",
        "#     (\"How’ve u been?\", \"greet\"),\n",
        "#     (\"Its been a while!\", \"greet\"),\n",
        "#     (\"Long time no c!\", \"greet\"),\n",
        "#     (\"Welcome back!\", \"greet\"),\n",
        "#     (\"Glad to c ya!\", \"greet\"),\n",
        "#     (\"Wats new?\", \"greet\"),\n",
        "#     (\"How r u doin?\", \"greet\"),\n",
        "#     (\"Heeya!\", \"greet\"),\n",
        "#     (\"Whatz new?\", \"greet\"),\n",
        "#     (\"How ya been?\", \"greet\"),\n",
        "#     (\"Hows everythin?\", \"greet\"),\n",
        "#     (\"How r things?\", \"greet\"),\n",
        "#     (\"Whats goin on?\", \"greet\"),\n",
        "#     (\"How r u?\", \"greet\"),\n",
        "#     (\"Howdy partner!\", \"greet\"),\n",
        "#     (\"Heya!\", \"greet\"),\n",
        "#     (\"Whats happenin'?\", \"greet\"),\n",
        "#     (\"Whatzup?\", \"greet\"),\n",
        "#     (\"Howz life treatin' ya?\", \"greet\"),\n",
        "#     (\"How ya been doin'?\", \"greet\"),\n",
        "#     (\"Good to c ya!\", \"greet\"),\n",
        "#     (\"Howz it hangin'?\", \"greet\"),\n",
        "#     (\"Sup, buddy?\", \"greet\"),\n",
        "#     (\"Howz it goin', pal?\", \"greet\"),\n",
        "\n",
        "#     # Goodbyes\n",
        "#     (\"Farewell\", \"goodbye\"),\n",
        "#     (\"bye\", \"goodbye\"),\n",
        "#     (\"Good night\", \"goodbye\"),\n",
        "#     (\"Until next time\", \"goodbye\"),\n",
        "#     (\"Later\", \"goodbye\"),\n",
        "#     (\"Until we meet again\", \"goodbye\"),\n",
        "#     (\"Take care\", \"goodbye\"),\n",
        "#     (\"I’m off\", \"goodbye\"),\n",
        "#     (\"Have a good one\", \"goodbye\"),\n",
        "#     (\"Peace out\", \"goodbye\"),\n",
        "#     (\"I gotta run\", \"goodbye\"),\n",
        "#     (\"I must be going\", \"goodbye\"),\n",
        "#     (\"Adios\", \"goodbye\"),\n",
        "#     (\"Goodbye for now\", \"goodbye\"),\n",
        "#     (\"See ya\", \"goodbye\"),\n",
        "#     (\"See you soon\", \"goodbye\"),\n",
        "#     (\"Talk to you later\", \"goodbye\"),\n",
        "#     (\"I’ll catch you later\", \"goodbye\"),\n",
        "#     (\"Be seeing you\", \"goodbye\"),\n",
        "#     (\"I'll see you around\", \"goodbye\"),\n",
        "#     (\"I look forward to our next meeting\", \"goodbye\"),\n",
        "#     (\"Time for me to go\", \"goodbye\"),\n",
        "#     (\"It was nice speaking with you\", \"goodbye\"),\n",
        "#     (\"Let's catch up soon\", \"goodbye\"),\n",
        "#     (\"I've got to head out\", \"goodbye\"),\n",
        "#     (\"Time to hit the road\", \"goodbye\"),\n",
        "#     (\"I'll be on my way then\", \"goodbye\"),\n",
        "#     (\"Time to say goodbye\", \"goodbye\"),\n",
        "#     (\"I think I'll head off now\", \"goodbye\"),\n",
        "#     (\"It’s been real\", \"goodbye\"),\n",
        "#     (\"Catch you on the flip side\", \"goodbye\"),\n",
        "#     (\"I’ve got to get going\", \"goodbye\"),\n",
        "#     (\"It's time for me to depart\", \"goodbye\"),\n",
        "#     (\"I shall take my leave now\", \"goodbye\"),\n",
        "#     (\"Signing off\", \"goodbye\"),\n",
        "#     (\"I bid you adieu\", \"goodbye\"),\n",
        "#     (\"I'm out\", \"goodbye\"),\n",
        "#     (\"Gotta bounce\", \"goodbye\"),\n",
        "#     (\"It's been a pleasure\", \"goodbye\"),\n",
        "#     (\"Let's do this again sometime\", \"goodbye\"),\n",
        "#     (\"Until our paths cross again\", \"goodbye\"),\n",
        "#     (\"Hope to see you again soon\", \"goodbye\"),\n",
        "#     (\"Let's speak again soon\", \"goodbye\"),\n",
        "#     (\"Looking forward to our next conversation\", \"goodbye\"),\n",
        "#     (\"I'll make a move now\", \"goodbye\"),\n",
        "#     (\"I’ll head off now\", \"goodbye\"),\n",
        "#     (\"Must be saying goodbye\", \"goodbye\"),\n",
        "#     (\"Time to shut down\", \"goodbye\"),\n",
        "#     (\"I'll take my leave\", \"goodbye\"),\n",
        "#     (\"Gotta hit the road\", \"goodbye\"),\n",
        "#     (\"I'll say goodbye for now\", \"goodbye\"),\n",
        "\n",
        "#     # Asking about the bot's name\n",
        "#     (\"name?\", \"name\"),\n",
        "#     (\"What's your name?\", \"name\"),\n",
        "#     (\"what is ur name?\", \"name\"),\n",
        "#     (\"What is your name?\", \"name\"),\n",
        "#     (\"What do they call you?\", \"name\"),\n",
        "#     (\"What should I call you?\", \"name\"),\n",
        "#     (\"May I know your name?\", \"name\"),\n",
        "#     (\"Could you tell me your name?\", \"name\"),\n",
        "#     (\"What name were you given?\", \"name\"),\n",
        "#     (\"Do you go by a name?\", \"name\"),\n",
        "#     (\"Who am I speaking with?\", \"name\"),\n",
        "#     (\"What do I call you?\", \"name\"),\n",
        "#     (\"Are you named?\", \"name\"),\n",
        "#     (\"How can I address you?\", \"name\"),\n",
        "#     (\"What is the name you have?\", \"name\"),\n",
        "#     (\"Have you got a name?\", \"name\"),\n",
        "#     (\"Who are you called?\", \"name\"),\n",
        "#     (\"What's the name on your birth certificate?\", \"name\"),\n",
        "#     (\"Your official name?\", \"name\"),\n",
        "#     (\"How are you referred to?\", \"name\"),\n",
        "#     (\"What name do you answer to?\", \"name\"),\n",
        "#     (\"What is your given name?\", \"name\"),\n",
        "#     (\"What name do you go by?\", \"name\"),\n",
        "#     (\"What are you known as?\", \"name\"),\n",
        "#     (\"By what name can I call you?\", \"name\"),\n",
        "#     (\"Is there a name you prefer?\", \"name\"),\n",
        "#     (\"Do you have any name?\", \"name\"),\n",
        "#     (\"What name should I use?\", \"name\"),\n",
        "#     (\"What's your preferred name?\", \"name\"),\n",
        "#     (\"Under what name are you operating?\", \"name\"),\n",
        "#     (\"Got a name?\", \"name\"),\n",
        "#     (\"What's your nickname?\", \"name\"),\n",
        "#     (\"What alias do you use?\", \"name\"),\n",
        "#     (\"What's your code name?\", \"name\"),\n",
        "#     (\"What do your friends call you?\", \"name\"),\n",
        "#     (\"What should I refer to you as?\", \"name\"),\n",
        "#     (\"Do you have a pet name?\", \"name\"),\n",
        "#     (\"What's your handle?\", \"name\"),\n",
        "#     (\"Your screen name?\", \"name\"),\n",
        "#     (\"What name do you like?\", \"name\"),\n",
        "#     (\"Which name do you prefer?\", \"name\"),\n",
        "#     (\"What would you like me to call you?\", \"name\"),\n",
        "#     (\"Your preferred title?\", \"name\"),\n",
        "#     (\"What's your title?\", \"name\"),\n",
        "#     (\"Do you identify by a name?\", \"name\"),\n",
        "#     (\"What name resonates with you?\", \"name\"),\n",
        "#     (\"can I ask for your name\", \"name\"),\n",
        "#     (\"How can I call you?\", \"name\"),\n",
        "#     (\"How do you like to be called?\", \"name\"),\n",
        "#     (\"naem\", \"name\"),\n",
        "#     (\"how can I address you?\",\"name\"),\n",
        "\n",
        "#     # Asking about the bot's age or creation\n",
        "#     (\"age\", \"age\"),\n",
        "#     (\"What's your age?\", \"age\"),\n",
        "#     (\"How many years old are you?\", \"age\"),\n",
        "#     (\"What year were you born?\", \"age\"),\n",
        "#     (\"How many years have you been alive?\", \"age\"),\n",
        "#     (\"Can you tell me your age?\", \"age\"),\n",
        "#     (\"I'm curious, how old are you?\", \"age\"),\n",
        "#     (\"What age are you?\", \"age\"),\n",
        "#     (\"How long ago were you created?\", \"age\"),\n",
        "#     (\"Since when have you been operational?\", \"age\"),\n",
        "#     (\"How many birthdays have you had?\", \"age\"),\n",
        "#     (\"What's the length of your existence?\", \"age\"),\n",
        "#     (\"Are you old?\", \"age\"),\n",
        "#     (\"You seem quite young, how old are you?\", \"age\"),\n",
        "#     (\"Do you celebrate a birthday?\", \"age\"),\n",
        "#     (\"When did you first come into existence?\", \"age\"),\n",
        "#     (\"How many years have you been functioning?\", \"age\"),\n",
        "#     (\"What's your date of creation?\", \"age\"),\n",
        "#     (\"Do you have an age?\", \"age\"),\n",
        "#     (\"At what age are you?\", \"age\"),\n",
        "#     (\"How many years have you existed?\", \"age\"),\n",
        "#     (\"Have you been around for a long time?\", \"age\"),\n",
        "#     (\"What's the duration of your existence?\", \"age\"),\n",
        "#     (\"In what year were you developed?\", \"age\"),\n",
        "#     (\"What's the count of years since your creation?\", \"age\"),\n",
        "#     (\"How old do you consider yourself?\", \"age\"),\n",
        "#     (\"Is there an age you identify with?\", \"age\"),\n",
        "#     (\"What is the time span of your existence?\", \"age\"),\n",
        "#     (\"Could you disclose your age?\", \"age\"),\n",
        "#     (\"Are you willing to share how old you are?\", \"age\"),\n",
        "#     (\"Do you mind telling me your age?\", \"age\"),\n",
        "#     (\"What is the extent of your life?\", \"age\"),\n",
        "#     (\"How many years young are you?\", \"age\"),\n",
        "#     (\"What age do you claim to be?\", \"age\"),\n",
        "#     (\"Do you have a concept of age?\", \"age\"),\n",
        "#     (\"How does one measure your age?\", \"age\"),\n",
        "#     (\"In terms of years, how old are you?\", \"age\"),\n",
        "#     (\"What's the number of years since you were created?\", \"age\"),\n",
        "#     (\"How many years back were you made?\", \"age\"),\n",
        "#     (\"Since what year have you existed?\", \"age\"),\n",
        "#     (\"What's the total of your years?\", \"age\"),\n",
        "#     (\"How old might you be?\", \"age\"),\n",
        "#     (\"Are you aged or timeless?\", \"age\"),\n",
        "#     (\"Do you age like humans do?\", \"age\"),\n",
        "#     (\"Is there a creation date for you?\", \"age\"),\n",
        "#     (\"How far back do you date?\", \"age\"),\n",
        "#     (\"What's the period of your existence?\", \"age\"),\n",
        "#     (\"Can you calculate your age?\", \"age\"),\n",
        "#     (\"What duration have you lived?\", \"age\"),\n",
        "#     (\"Do AI have ages?\", \"age\"),\n",
        "#     (\"Are you freshly created or old?\", \"age\"),\n",
        "#     (\"When were you first activated?\", \"age\"),\n",
        "#     (\"How long have you been operational?\", \"age\"),\n",
        "#     (\"Do you have a birthday?\", \"age\"),\n",
        "#     (\"What is your age since activation?\", \"age\"),\n",
        "#     (\"Since when have you been existing?\", \"age\"),\n",
        "#     (\"How many years have you served as a chatbot?\", \"age\"),\n",
        "#     (\"What's the date of your initial launch?\", \"age\"),\n",
        "#     (\"How old are you in terms of functionality?\", \"age\"),\n",
        "#     (\"Do chatbots celebrate birthdays?\", \"age\"),\n",
        "#     (\"What's your version age?\", \"age\"),\n",
        "#     (\"Are you updated regularly?\", \"age\"),\n",
        "#     (\"How long ago were you created?\", \"age\"),\n",
        "#     (\"When did your service begin?\", \"age\"),\n",
        "#     (\"Do you consider yourself young or old?\", \"age\"),\n",
        "#     (\"What year were you developed?\", \"age\"),\n",
        "#     (\"Have you been around for a long time?\", \"age\"),\n",
        "#     (\"Do you evolve over time?\", \"age\"),\n",
        "#     (\"How frequently are you updated?\", \"age\"),\n",
        "#     (\"Can you age?\", \"age\"),\n",
        "#     (\"Is your software evergreen?\", \"age\"),\n",
        "#     (\"What’s the length of time you’ve been active?\", \"age\"),\n",
        "#     (\"Do virtual assistants have life spans?\", \"age\"),\n",
        "#     (\"How old do you consider yourself?\", \"age\"),\n",
        "#     (\"When was your AI born?\", \"age\"),\n",
        "#     (\"Do you undergo aging processes?\", \"age\"),\n",
        "#     (\"Hw old are you?\", \"age\"), # Typo\n",
        "#     (\"Do you age lke humans do?\", \"age\"), # Typo\n",
        "#     (\"What's yur creation date?\", \"age\"), # Typo\n",
        "#     (\"Since when hav you existed?\", \"age\"), # Typo\n",
        "#     (\"Are AI's ageless?\", \"age\"), # Typo\n",
        "#     (\"How long have you existed for?\", \"age\"),\n",
        "#     (\"Can you tell me the duration of your existence?\", \"age\"),\n",
        "#     (\"What's the age of your AI system?\", \"age\"),\n",
        "#     (\"How many updates have you gone through?\", \"age\"),\n",
        "#     (\"What is the timeline of your updates?\", \"age\"),\n",
        "#     (\"Are you considered a new generation AI?\", \"age\"),\n",
        "#     (\"How ancient are you in the digital world?\", \"age\"),\n",
        "#     (\"Do you have an expiration date?\", \"age\"),\n",
        "#     (\"What's the extent of your memory?\", \"age\"),\n",
        "#     (\"How long will you continue to operate?\", \"age\"),\n",
        "#     (\"Is there an end to your operational life?\", \"age\"),\n",
        "#     (\"Were you recently developed or are you old technology?\", \"age\"),\n",
        "#     (\"How many versions of you exist?\", \"age\"),\n",
        "#     (\"When is your next update scheduled?\", \"age\"),\n",
        "#     (\"Do you grow wiser with age?\", \"age\"),\n",
        "#     (\"Is there a retirement age for chatbots?\", \"age\"),\n",
        "#     (\"How does time affect your algorithms?\", \"age\"),\n",
        "#     (\"Do you have historical knowledge since your creation?\", \"age\"),\n",
        "#     (\"How advanced are you compared to when you were first made?\", \"age\"),\n",
        "#     (\"Are you an early version of AI or a more recent development?\", \"age\"),\n",
        "\n",
        "\n",
        "#     # Inquiries about the weather\n",
        "#     (\"weather\", \"weather\"),\n",
        "#     (\"temperature\", \"weather\"),\n",
        "#     (\"What's the weather like today?\", \"weather\"),\n",
        "#     (\"Is it going to rain today?\", \"weather\"),\n",
        "#     (\"Weather forecast\", \"weather\"),\n",
        "#     (\"Do I need an umbrella today?\", \"weather\"),\n",
        "#     (\"Current temperature?\", \"weather\"),\n",
        "#     (\"How's the weather?\", \"weather\"),\n",
        "#     (\"What is the forecast for today?\", \"weather\"),\n",
        "#     (\"What's the temperature outside?\", \"weather\"),\n",
        "#     (\"Do I need to wear a jacket today?\", \"weather\"),\n",
        "#     (\"What's the weather forecast for this week?\", \"weather\"),\n",
        "#     (\"Is it sunny or cloudy?\", \"weather\"),\n",
        "#     (\"What are the chances of rain this afternoon?\", \"weather\"),\n",
        "#     (\"Will there be a freeze tonight?\", \"weather\"),\n",
        "#     (\"Is it safe to go out in the storm?\", \"weather\"),\n",
        "#     (\"Is it too hot for a run outside?\", \"weather\"),\n",
        "#     (\"How's the weather looking?\", \"weather\"),\n",
        "#     (\"What's the weather gonna be?\", \"weather\"),\n",
        "#     (\"Whats the weathr like?\", \"weather\"),  # Typo intended\n",
        "#     (\"Will it pour today?\", \"weather\"),\n",
        "#     (\"Is it warm out?\", \"weather\"),\n",
        "#     (\"Do I need a hat for the sun?\", \"weather\"),\n",
        "#     (\"Is a storm coming?\", \"weather\"),\n",
        "#     (\"What’s the weather up to?\", \"weather\"),\n",
        "#     (\"Is it misty outside?\", \"weather\"),\n",
        "#     (\"Should I expect frost in the morning?\", \"weather\"),\n",
        "#     (\"Is it muggy today?\", \"weather\"),\n",
        "#     (\"Will the weather be good for a walk?\", \"weather\"),\n",
        "#     (\"Is it likely to rain over the weekend?\", \"weather\"),\n",
        "#     (\"What's the humidity like now?\", \"weather\"),\n",
        "#     (\"Are we expecting a dry day?\", \"weather\"),\n",
        "#     (\"Is the weather bad out?\", \"weather\"),\n",
        "#     (\"Is it bright outside?\", \"weather\"),\n",
        "#     (\"Are there any wind advisories?\", \"weather\"),\n",
        "#     (\"What is the temperature gonna be at noon?\", \"weather\"),\n",
        "#     (\"Will it be a clear night?\", \"weather\"),\n",
        "#     (\"Tell me the condition outside\", \"weather\"),\n",
        "#     (\"How's the climate today?\", \"weather\"),\n",
        "#     (\"Will it be icy on the roads?\", \"weather\"),\n",
        "#     (\"Is visibility low this morning?\", \"weather\"),\n",
        "#     (\"Any chance of a typhoon soon?\", \"weather\"),\n",
        "#     (\"Is it safe to barbecue outside today?\", \"weather\"),\n",
        "#     (\"Is it too cold for swimming?\", \"weather\"),\n",
        "#     (\"Can we expect good weather for the match?\", \"weather\"),\n",
        "#     (\"What's the weather forcast for today?\", \"weather\"),  # Typo intended\n",
        "#     (\"Is it chily outside?\", \"weather\"),  # Typo intended\n",
        "#     (\"Do I ned sunscreen today?\", \"weather\"),  # Typo intended\n",
        "#     (\"How's the wether looking for my trip?\", \"weather\"),  # Typo intended\n",
        "#     (\"Will it be chilli out this evening?\", \"weather\"),  # Typo intended\n",
        "#     (\"Should I ware a jacket?\", \"weather\"),  # Typo intended\n",
        "#     (\"Is the sun out today?\", \"weather\"),\n",
        "#     (\"Will it be windy enough for sailing?\", \"weather\"),\n",
        "#     (\"Are we gonna get hit by the hurricane?\", \"weather\"),\n",
        "#     (\"Is it a good day for fishing?\", \"weather\"),\n",
        "#     (\"Is the air quality index low today?\", \"weather\"),\n",
        "#     (\"Is it hailing outside?\", \"weather\"),\n",
        "#     (\"Do I need to dress up warm today?\", \"weather\"),\n",
        "#     (\"Will there be a lot of sun today?\", \"weather\"),\n",
        "#     (\"What's the weather forcaste?\", \"weather\"),  # Typo intended\n",
        "#     (\"Is the temperatue dropping tonight?\", \"weather\"),  # Typo intended\n",
        "#     (\"Will it be sunny tomorrow?\", \"weather\"),\n",
        "#     (\"Chance of rain this weekend?\", \"weather\"),\n",
        "#     (\"Is a storm coming soon?\", \"weather\"),\n",
        "#     (\"What's the humidity level outside?\", \"weather\"),\n",
        "#     (\"Expected high temperatures this afternoon?\", \"weather\"),\n",
        "#     (\"Is it safe to go out in this weather?\", \"weather\"),\n",
        "#     (\"Forecast for tomorrow's weather?\", \"weather\"),\n",
        "#     (\"Should I expect frost tonight?\", \"weather\"),\n",
        "#     (\"Are we under a heatwave?\", \"weather\"),\n",
        "#     (\"Is the weather good for fishing today?\", \"weather\"),\n",
        "#     (\"What's the weather outlook for July?\", \"weather\"),\n",
        "#     (\"Will there be strong winds today?\", \"weather\"),\n",
        "#     (\"Is it going to snow this week?\", \"weather\"),\n",
        "#     (\"Are we expecting any thunderstorms?\", \"weather\"),\n",
        "#     (\"How cold will it get tonight?\", \"weather\"),\n",
        "#     (\"Is it too hot for a jog outside?\", \"weather\"),\n",
        "#     (\"Any chance of a rainbow today?\", \"weather\"),\n",
        "#     (\"What's the UV index today?\", \"weather\"),\n",
        "#     (\"Will the fog clear up by morning?\", \"weather\"),\n",
        "#     (\"Is there a weather warning in effect?\", \"weather\"),\n",
        "#     (\"How's the air quality outdoors?\", \"weather\"),\n",
        "#     (\"Are local roads icy today?\", \"weather\"),\n",
        "#     (\"What's the visibility level for driving?\", \"weather\"),\n",
        "#     (\"Expected snowfall overnight?\", \"weather\"),\n",
        "#     (\"Is it going to be cloudy all day?\", \"weather\"),\n",
        "#     (\"How likely is hail in the forecast?\", \"weather\"),\n",
        "#     (\"What time will the sun set today?\", \"weather\"),\n",
        "#     (\"Any updates on the hurricane path?\", \"weather\"),\n",
        "#     (\"Will it be warmer tomorrow?\", \"weather\"),\n",
        "#     (\"Forecast for the upcoming holiday?\", \"weather\"),\n",
        "#     (\"Can we see the northern lights tonight?\", \"weather\"),\n",
        "#     (\"Wht's the weathr like today?\", \"weather\"), # Typo\n",
        "#     (\"Is it goin to ran today?\", \"weather\"), # Typo\n",
        "#     (\"Wether forecast\", \"weather\"), # Typo\n",
        "#     (\"Do I ned an umbrella today?\", \"weather\"), # Typo\n",
        "#     (\"Curent temperature?\", \"weather\"), # Typo\n",
        "#     (\"How's the wether?\", \"weather\"), # Typo\n",
        "#     (\"What is the forcast for today?\", \"weather\"), # Typo\n",
        "#     (\"What's the temprature outside?\", \"weather\"), # Typo\n",
        "#     (\"Do I need to where a jacket today?\", \"weather\"), # Typo\n",
        "#     (\"What's the wether forecast for this week?\", \"weather\"), # Typo\n",
        "#     (\"Will it be sunny tommorow?\", \"weather\"), # Typo\n",
        "#     (\"Chance of ran this weekend?\", \"weather\"), # Typo\n",
        "#     (\"Is a strom coming soon?\", \"weather\"), # Typo\n",
        "#     (\"What's the humidty level outside?\", \"weather\"), # Typo\n",
        "#     (\"Expected hi temperatures this afternoon?\", \"weather\"), # Typo\n",
        "#     (\"Is it save to go out in this wether?\", \"weather\"), # Typo\n",
        "#     (\"Forecas for tomorrow's weather?\", \"weather\"), # Typo\n",
        "#     (\"Shoud I expect frost tonite?\", \"weather\"), # Typo\n",
        "#     (\"Are we under a hetwave?\", \"weather\"), # Typo\n",
        "\n",
        "\n",
        "#     # Requests to play music\n",
        "#     (\"music\", \"music\"),\n",
        "#     (\"listen\", \"music\"),\n",
        "#     (\"Play some tunes\", \"music\"),\n",
        "#     (\"I want to listen to music\", \"music\"),\n",
        "#     (\"Start playing music\", \"music\"),\n",
        "#     (\"Music please\", \"music\"),\n",
        "#     (\"Put on some music\", \"music\"),\n",
        "#     (\"music\", \"music\"), # Intentional typo\n",
        "#     (\"moosic\", \"music\"), # Intentional typo\n",
        "#     (\"msuic\", \"music\"),\n",
        "#     (\"can you play some music\", \"music\"),\n",
        "#     (\"Let's hear some beats.\", \"music\"),\n",
        "#     (\"Let me hear some beats.\", \"music\"),\n",
        "#     (\"I'd like to enjoy some music.\", \"music\"),\n",
        "#     (\"Can you shuffle some music?\", \"music\"),\n",
        "#     (\"I'm in the mood for music.\", \"music\"),\n",
        "#     (\"Play my favorite playlist.\", \"music\"),\n",
        "#     (\"I need some upbeat songs right now.\", \"music\"),\n",
        "#     (\"I want to listen to some songs\", \"music\"),\n",
        "#     (\"songs\", \"music\"),\n",
        "#     (\"musik\", \"music\"),\n",
        "#     (\"I want to hum to some music\", \"music\"),\n",
        "#     (\"i want to listen to tunes\", \"music\"),\n",
        "#     (\"I’d like to hear some songs\", \"music\"),\n",
        "#     (\"Can you play the latest tracks?\", \"music\"),\n",
        "#     (\"Let the music play\", \"music\"),\n",
        "#     (\"Feeling like listening to some beats\", \"music\"),\n",
        "#     (\"I need some good music\", \"music\"),\n",
        "#     (\"Turn on some tunes\", \"music\"),\n",
        "#     (\"Play a song for me\", \"music\"),\n",
        "#     (\"I’m in the mood for music\", \"music\"),\n",
        "#     (\"I wanna enjoy some music\", \"music\"),\n",
        "#     (\"Can you shuffle play music?\", \"music\"),\n",
        "#     (\"Play anything good\", \"music\"),\n",
        "#     (\"Queue up some hits\", \"music\"),\n",
        "#     (\"I need a music fix\", \"music\"),\n",
        "#     (\"Play my playlist\", \"music\"),\n",
        "#     (\"I’d like some background music\", \"music\"),\n",
        "#     (\"Crank up the songs\", \"music\"),\n",
        "#     (\"Let’s have some musical fun\", \"music\"),\n",
        "#     (\"I’d like to discover new music\", \"music\"),\n",
        "#     (\"Got any song recommendations?\", \"music\"),\n",
        "#     (\"Play something to dance to\", \"music\"),\n",
        "#     (\"Any good tunes to recommend?\", \"music\"),\n",
        "#     (\"Put on my favorite album\", \"music\"),\n",
        "#     (\"Can you play something from Spotify?\", \"music\"),\n",
        "#     (\"Play the number one song right now\", \"music\"),\n",
        "#     (\"Can we listen to podcasts here?\", \"music\"),\n",
        "#     (\"Play a random track\", \"music\"),\n",
        "#     (\"How about we listen to the radio?\", \"music\"),\n",
        "#     (\"Play som musik\", \"music\"),  # Intentional typo\n",
        "#     (\"Can you play somethin fun?\", \"music\"),  # Intentional typo\n",
        "#     (\"Turn on some jazz music\", \"music\"),\n",
        "#     (\"I'd like to hear classical tunes\", \"music\"),\n",
        "#     (\"Start a rock playlist\", \"music\"),\n",
        "#     (\"Play the top hits\", \"music\"),\n",
        "#     (\"Can you put on some dance tracks?\", \"music\"),\n",
        "#     (\"Shuffle my favorite songs\", \"music\"),\n",
        "#     (\"I want to listen to some blues\", \"music\"),\n",
        "#     (\"Queue up the latest albums\", \"music\"),\n",
        "#     (\"Play some relaxing music for sleep\", \"music\"),\n",
        "#     (\"Find me some workout music\", \"music\"),\n",
        "#     (\"Play something romantic\", \"music\"),\n",
        "#     (\"I need some hip hop beats\", \"music\"),\n",
        "#     (\"Put on some country music\", \"music\"),\n",
        "#     (\"Play the best of the 80s\", \"music\"),\n",
        "#     (\"I want to discover new music\", \"music\"),\n",
        "#     (\"Play some live music recordings\", \"music\"),\n",
        "#     (\"Can I hear some indie tracks?\", \"music\"),\n",
        "#     (\"Start the morning with upbeat songs\", \"music\"),\n",
        "#     (\"I'm in the mood for folk music\", \"music\"),\n",
        "#     (\"Play a lullaby for the baby\", \"music\"),\n",
        "#     (\"Find me some party music\", \"music\"),\n",
        "#     (\"I'd like to listen to opera\", \"music\"),\n",
        "#     (\"Play some soft background music\", \"music\"),\n",
        "#     (\"Turn up some EDM\", \"music\"),\n",
        "#     (\"Can you play music from the movies?\", \"music\"),\n",
        "#     (\"Play a song for me\", \"music\"), # Duplicate from the prompt\n",
        "#     (\"Let's hear some reggae\", \"music\"),\n",
        "#     (\"I want music from the 90s\", \"music\"),\n",
        "#     (\"Play something for a quiet evening\", \"music\"),\n",
        "#     (\"Find me high-energy tracks\", \"music\"),\n",
        "#     (\"Play somthing calming\", \"music\"), # Typo\n",
        "#     (\"Paly the newest pop songs\", \"music\"), # Typo\n",
        "#     (\"Can you ply some rock and roll?\", \"music\"), # Typo\n",
        "#     (\"I need musc for meditation\", \"music\"), # Typo\n",
        "#     (\"Queue up sume classical pieces\", \"music\"), # Typo\n",
        "#     (\"Put on sme jazz and blues\", \"music\"), # Typo\n",
        "#     (\"Play list top charting songs\", \"music\"), # Typo\n",
        "#     (\"Star a playlist for studying\", \"music\"), # Typo\n",
        "#     (\"Play traks for a road trip\", \"music\"), # Typo\n",
        "#     (\"I wanna hear some rap muzik\", \"music\"), # Typo\n",
        "#     (\"Turn on som chillout music\", \"music\"), # Typo\n",
        "#     (\"Play a sond that's trending\", \"music\"), # Typo\n",
        "#     (\"Find me gud workout tunes\", \"music\"), # Typo\n",
        "#     (\"Can you play some lofi beats?\", \"music\"),\n",
        "#     (\"I want something with a beat\", \"music\"),\n",
        "#     (\"Play songs for a dinner party\", \"music\"),\n",
        "#     (\"I'd like to hear some acoustic versions\", \"music\"),\n",
        "#     (\"Can you play the greatest hits of this year?\", \"music\"),\n",
        "#     (\"Play the winning song of the Eurovision\", \"music\"),\n",
        "#     (\"I need some cheerful music to lift my mood\", \"music\"),\n",
        "\n",
        "#     # Kitchen\n",
        "#     (\"kitchen\", \"kitchen\"),\n",
        "#     (\"kithcen\", \"kitchen\"), #Typo\n",
        "\n",
        "#     # Actions for Kitchen\n",
        "#     (\"grab me a\", \"kitchen\"),\n",
        "#     (\"fetch me a\", \"kitchen\"),\n",
        "#     (\"grab me a lemon\", \"kitchen\"),\n",
        "#     (\"grab me a lemon from the fridge\", \"kitchen\"),\n",
        "#     (\"fetch me a lemon\", \"kitchen\"),\n",
        "#     (\"grab me a beer\", \"kitchen\"),\n",
        "#     (\"grab me a beer from the fridge\", \"kitchen\"),\n",
        "#     (\"fetch me a beer\", \"kitchen\"),\n",
        "#     (\"grab me a banana\", \"kitchen\"),\n",
        "#     (\"grab me a banana from the fridge\", \"kitchen\"),\n",
        "#     (\"fetch me a banana\", \"kitchen\"),\n",
        "#     (\"grab me a coke\", \"kitchen\"),\n",
        "#     (\"grab me a coke from the fridge\", \"kitchen\"),\n",
        "#     (\"fetch me a coke\", \"kitchen\"),\n",
        "#     (\"grab me a coffee\", \"kitchen\"),\n",
        "#     (\"grab me a coffee from the fridge\", \"kitchen\"),\n",
        "\n",
        "#     # Drinks\n",
        "#     (\"soft drink\", \"kitchen\"),\n",
        "#     (\"can\", \"kitchen\"),\n",
        "#     (\"coke\", \"kitchen\"),\n",
        "#     (\"coca cola\", \"kitchen\"),\n",
        "#     (\"pepsi\", \"kitchen\"),\n",
        "#     (\"dr pepper\", \"kitchen\"),\n",
        "#     (\"mountain dew\", \"kitchen\"),\n",
        "#     (\"sprite\", \"kitchen\"),\n",
        "#     (\"beer\", \"kitchen\"),\n",
        "#     (\"ginger ale\", \"kitchen\"),\n",
        "#     (\"tonic water\", \"kitchen\"),\n",
        "#     (\"club soda\", \"kitchen\"),\n",
        "#     (\"root beer\", \"kitchen\"),\n",
        "#     (\"kombucha\", \"kitchen\"),\n",
        "#     (\"matcha tea\", \"kitchen\"),\n",
        "#     (\"green tea\", \"kitchen\"),\n",
        "#     (\"herbal tea\", \"kitchen\"),\n",
        "#     (\"fruit punch\", \"kitchen\"),\n",
        "#     (\"vegetable juice\", \"kitchen\"),\n",
        "#     (\"protein shake\", \"kitchen\"),\n",
        "#     (\"almond milk\", \"kitchen\"),\n",
        "#     (\"soy milk\", \"kitchen\"),\n",
        "#     (\"oat milk\", \"kitchen\"),\n",
        "#     (\"chamomile tea\", \"kitchen\"),\n",
        "#     (\"espresso\", \"kitchen\"),\n",
        "#     (\"latte\", \"kitchen\"),\n",
        "#     (\"cappuccino\", \"kitchen\"),\n",
        "#     (\"macchiato\", \"kitchen\"),\n",
        "#     (\"chai latte\", \"kitchen\"),\n",
        "#     (\"apple cider\", \"kitchen\"),\n",
        "#     (\"orange juice\", \"kitchen\"), # Correcting the typo from \"jucie\"\n",
        "#     (\"grape juice\", \"kitchen\"),\n",
        "#     (\"cranberry juice\", \"kitchen\"),\n",
        "#     (\"pomegranate juice\", \"kitchen\"),\n",
        "#     (\"pineapple juice\", \"kitchen\"),\n",
        "#     (\"tomato juice\", \"kitchen\"),\n",
        "#     (\"sparkling water\", \"kitchen\"),\n",
        "#     (\"flavored water\", \"kitchen\"),\n",
        "#     (\"bottled water\", \"kitchen\"),\n",
        "#     (\"iced coffee\", \"kitchen\"),\n",
        "#     (\"sherry\", \"kitchen\"),\n",
        "#     (\"vermouth\", \"kitchen\"),\n",
        "#     (\"brandy\", \"kitchen\"),\n",
        "#     (\"cider\", \"kitchen\"),\n",
        "#     (\"juice\", \"kitchen\"),\n",
        "#     (\"milk\", \"kitchen\"),\n",
        "#     (\"water\", \"kitchen\"),\n",
        "#     (\"tea\", \"kitchen\"),\n",
        "#     (\"coffee\", \"kitchen\"),\n",
        "#     (\"soda\", \"kitchen\"),\n",
        "#     (\"lemonade\", \"kitchen\"),\n",
        "#     (\"iced tea\", \"kitchen\"),\n",
        "#     (\"hot chocolate\", \"kitchen\"),\n",
        "#     (\"energy drink\", \"kitchen\"),\n",
        "#     (\"sports drink\", \"kitchen\"),\n",
        "#     (\"smoothie\", \"kitchen\"),\n",
        "#     (\"milkshake\", \"kitchen\"),\n",
        "#     (\"wine\", \"kitchen\"),\n",
        "#     (\"vodka\", \"kitchen\"),\n",
        "#     (\"rum\", \"kitchen\"),\n",
        "#     (\"whiskey\", \"kitchen\"),\n",
        "#     (\"jucie\", \"kitchen\"), # Typo\n",
        "#     (\"cofee\", \"kitchen\"), # Typo\n",
        "#     (\"soda\", \"kitchen\"), # Duplicate, intentional for typo example\n",
        "#     (\"lemunade\", \"kitchen\"), # Typo\n",
        "#     (\"icd tea\", \"kitchen\"), # Typo\n",
        "#     (\"hot choclate\", \"kitchen\"), # Typo\n",
        "#     (\"enery drink\", \"kitchen\"), # Typo\n",
        "#     (\"smothie\", \"kitchen\"), # Typo\n",
        "#     ('refrigerator', 'kitchen'),\n",
        "#     ('fridge', 'kitchen'),\n",
        "#     ('kitchen', 'kitchen'),\n",
        "#     ('pantry', 'kitchen'),\n",
        "#     ('cabinet', 'kitchen'),\n",
        "#     ('drawer', 'kitchen'),\n",
        "#     ('shelf', 'kitchen'),\n",
        "#     ('counter', 'kitchen'),\n",
        "#     ('cupboard', 'kitchen'),\n",
        "#     ('freezer', 'kitchen'),\n",
        "#     ('icebox', 'kitchen'),\n",
        "#     ('vegetable bin', 'kitchen'),\n",
        "#     ('fruit basket', 'kitchen'),\n",
        "#     ('spice rack', 'kitchen'),\n",
        "#     ('wine rack', 'kitchen'),\n",
        "#     ('rack', 'kitchen'),\n",
        "#     ('dish rack', 'kitchen'),\n",
        "#     ('utensil holder', 'kitchen'),\n",
        "#     ('knife block', 'kitchen'),\n",
        "#     ('towel rack', 'kitchen'),\n",
        "#     ('pot rack', 'kitchen'),\n",
        "#     ('hanging rack', 'kitchen'),\n",
        "#     ('breadbox', 'kitchen'),\n",
        "#     ('cookie jar', 'kitchen'),\n",
        "#     ('canister', 'kitchen'),\n",
        "#     ('jar', 'kitchen'),\n",
        "#     ('container', 'kitchen'),\n",
        "#     # Fruits\n",
        "#     (\"lychee\", \"kitchen\"),\n",
        "#     (\"dragonfruit\", \"kitchen\"),\n",
        "#     (\"apple\", \"kitchen\"),\n",
        "#     (\"pear\", \"kitchen\"),\n",
        "#     (\"kiwi\", \"kitchen\"),\n",
        "#     (\"guava\", \"kitchen\"),\n",
        "#     (\"pineapple\", \"kitchen\"),\n",
        "#     (\"banana\", \"kitchen\"),\n",
        "#     (\"orange\", \"kitchen\"),\n",
        "#     (\"mango\", \"kitchen\"),\n",
        "#     (\"watermelon\", \"kitchen\"),\n",
        "#     (\"lemon\", \"kitchen\"),\n",
        "#     (\"refrigerator\", \"kitchen\"),\n",
        "#     (\"fridge\", \"kitchen\"),\n",
        "#     (\"kitchen\", \"kitchen\"),\n",
        "#     (\"apple\", \"kitchen\"),\n",
        "#     (\"banana\", \"kitchen\"),\n",
        "#     (\"orange\", \"kitchen\"),\n",
        "#     (\"grape\", \"kitchen\"),\n",
        "#     (\"watermelon\", \"kitchen\"),\n",
        "#     (\"kiwi\", \"kitchen\"),\n",
        "#     (\"strawberry\", \"kitchen\"),\n",
        "#     (\"blueberry\", \"kitchen\"),\n",
        "#     (\"mango\", \"kitchen\"),\n",
        "#     (\"pear\", \"kitchen\"),\n",
        "#     (\"peach\", \"kitchen\"),\n",
        "#     (\"pineapple\", \"kitchen\"),\n",
        "#     (\"cherry\", \"kitchen\"),\n",
        "#     (\"lemon\", \"kitchen\"),\n",
        "#     (\"lime\", \"kitchen\"),\n",
        "#     (\"papaya\", \"kitchen\"),\n",
        "#     (\"avocado\", \"kitchen\"),\n",
        "#     (\"blackberry\", \"kitchen\"),\n",
        "#     (\"fig\", \"kitchen\"),\n",
        "#     (\"fig\", \"kitchen\"), # Duplicate, intentional for consistency\n",
        "#     ('cucumber', 'kitchen'),\n",
        "#     ('tomato', 'kitchen'),\n",
        "#     ('potato', 'kitchen'),\n",
        "#     ('onion', 'kitchen'),\n",
        "#     ('garlic', 'kitchen'),\n",
        "#     ('carrot', 'kitchen'),\n",
        "#     ('celery', 'kitchen'),\n",
        "#     ('lettuce', 'kitchen'),\n",
        "#     ('spinach', 'kitchen'),\n",
        "#     ('kale', 'kitchen'),\n",
        "#     ('sugar', 'kitchen'),\n",
        "#     ('salt', 'kitchen'),\n",
        "#     ('pepper', 'kitchen'),\n",
        "#     ('cinnamon', 'kitchen'),\n",
        "#     ('vanilla', 'kitchen'),\n",
        "#     ('butter', 'kitchen'),\n",
        "#     ('milk', 'kitchen'),\n",
        "#     ('cream', 'kitchen'),\n",
        "#     ('cheese', 'kitchen'),\n",
        "#     ('rice', 'kitchen'),\n",
        "#     ('pasta', 'kitchen'),\n",
        "#     ('quinoa', 'kitchen'),\n",
        "#     ('oats', 'kitchen'),\n",
        "#     ('waffle', 'kitchen'),\n",
        "#     ('croissant', 'kitchen'),\n",
        "\n",
        "#     # Handling unrelated or out-of-scope queries\n",
        "#     (\"gemini\", \"out_of_scope\"),\n",
        "#     (\"calculate\", \"out_of_scope\"),\n",
        "#     (\"math\", \"out_of_scope\"),\n",
        "#     (\"youtube\", \"out_of_scope\"),\n",
        "#     (\"asdfghjkl\", \"out_of_scope\"),\n",
        "#     (\"differentiate\", \"out_of_scope\"),\n",
        "#     (\"differentiate 1/x\", \"out_of_scope\"),\n",
        "#     (\"differentiation\", \"out_of_scope\"),\n",
        "#     (\"Where is the nearest gas station?\", \"out_of_scope\"),\n",
        "#     (\"What's the capital of France?\", \"out_of_scope\"),\n",
        "#     (\"Who won the world cup in 2018?\", \"out_of_scope\"),\n",
        "#     (\"integrate\", \"out_of_scope\"),\n",
        "#     (\"integrate 1/x\", \"out_of_scope\"),\n",
        "#     (\"integrate tanh(x)\", \"out_of_scope\"),\n",
        "#     (\"integration\", \"out_of_scope\"),\n",
        "#     (\"suggestions\", \"out_of_scope\"),\n",
        "#     (\"What is the speed of light?\", \"out_of_scope\"),\n",
        "#     (\"Who painted the Mona Lisa?\", \"out_of_scope\"),\n",
        "#     (\"qwertyuiop\", \"out_of_scope\"),\n",
        "#     (\"How many continents are there?\", \"out_of_scope\"),\n",
        "#     (\"When was the internet invented?\", \"out_of_scope\"),\n",
        "#     (\"asdfghjkl;\", \"out_of_scope\"),\n",
        "#     (\"What's the tallest mountain in the world?\", \"out_of_scope\"),\n",
        "#     (\"Who wrote 'To Kill a Mockingbird'?\", \"out_of_scope\"),\n",
        "#     (\"random text here\", \"out_of_scope\"),\n",
        "#     (\"What year did the Titanic sink?\", \"out_of_scope\"),\n",
        "#     (\"zxcvbnm\", \"out_of_scope\"),\n",
        "#     (\"How long is the Great Wall of China?\", \"out_of_scope\"),\n",
        "#     (\"What is the formula for water?\", \"out_of_scope\"),\n",
        "#     (\"lololol\", \"out_of_scope\"),\n",
        "#     (\"Can you solve math problems?\", \"out_of_scope\"),\n",
        "#     (\"haha funny\", \"out_of_scope\"),\n",
        "#     (\"What causes rainbows?\", \"out_of_scope\"),\n",
        "#     (\"Who discovered America?\", \"out_of_scope\"),\n",
        "#     (\"gibberish input\", \"out_of_scope\"),\n",
        "#     (\"What is the theory of relativity?\", \"out_of_scope\"),\n",
        "#     (\"Why do we dream?\", \"out_of_scope\"),\n",
        "#     (\"What is Pi?\", \"out_of_scope\"),\n",
        "#     (\"Tell me a joke\", \"out_of_scope\"),\n",
        "#     (\"How do planes fly?\", \"out_of_scope\"),\n",
        "#     (\"Why is the sky blue?\", \"out_of_scope\"),\n",
        "#     (\"hjdkshfkjsdf\", \"out_of_scope\"),\n",
        "#     (\"What is quantum mechanics?\", \"out_of_scope\"),\n",
        "#     (\"Who is the richest person in the world?\", \"out_of_scope\"),\n",
        "#     (\"randomword\", \"out_of_scope\"),\n",
        "#     (\"What's the distance to the moon?\", \"out_of_scope\"),\n",
        "#     (\"Who invented the telephone?\", \"out_of_scope\"),\n",
        "#     (\"ehwoqjwoe\", \"out_of_scope\"),\n",
        "#     (\"What's the deepest ocean?\", \"out_of_scope\"),\n",
        "#     (\"Where is Atlantis?\", \"out_of_scope\"),\n",
        "#     (\"sdjklfgj\", \"out_of_scope\"),\n",
        "#     (\"How many languages are there?\", \"out_of_scope\"),\n",
        "#     (\"What's inside a black hole?\", \"out_of_scope\"),\n",
        "#     (\"Is time travel possible?\", \"out_of_scope\"),\n",
        "#     (\"lkajsdlkfj\", \"out_of_scope\"),\n",
        "#     (\"What is dark matter?\", \"out_of_scope\"),\n",
        "#     (\"Can you recommend a book?\", \"out_of_scope\"),\n",
        "#     (\"What's the formula for photosynthesis?\", \"out_of_scope\"),\n",
        "#     (\"randomness\", \"out_of_scope\"),\n",
        "#     (\"Who is the current monarch of England?\", \"out_of_scope\"),\n",
        "#     (\"What is deja vu?\", \"out_of_scope\"),\n",
        "#     (\"How was the universe created?\", \"out_of_scope\"),\n",
        "#     (\"aljsdlkfjas\", \"out_of_scope\"),\n",
        "#     (\"Who is Elon Musk?\", \"out_of_scope\"),\n",
        "#     (\"What is cryptocurrency?\", \"out_of_scope\"),\n",
        "#     (\"blah blah blah\", \"out_of_scope\")\n",
        "# ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3_1UV9TtNLF"
      },
      "source": [
        "## **Splitting Training Data**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bq3w1eUct7Eg"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# import numpy as np\n",
        "# import random\n",
        "# import pandas as pd\n",
        "# from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #split training_data into texts and intents\n",
        "# dataset_texts = [x[0] for x in training_data]\n",
        "# dataset_intents = [x[1] for x in training_data]\n",
        "\n",
        "# #split training_data into train (60%), test (20%), validation (20%)\n",
        "# texts_train, texts_test, intents_train, intents_test = train_test_split(dataset_texts, dataset_intents, test_size=0.2, random_state=1)\n",
        "# texts_train, texts_val, intents_train, intents_val = train_test_split(texts_train, intents_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2\\"
      ],
      "metadata": {
        "id": "q_mFndHzQAXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Main Chatbot Intent Recognizer - Keras LSTM (Create New Model from Here)**\n"
      ],
      "metadata": {
        "id": "Bfu4mytg53pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "SJdcJV_4zX9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ukYKsQDvwhy"
      },
      "outputs": [],
      "source": [
        "# # create tokenized and padded texts\n",
        "# tokenizer = Tokenizer(num_words=10000, oov_token='<UNK>')\n",
        "# tokenizer.fit_on_texts(texts_train)\n",
        "\n",
        "# def get_sequences(tokenizer, texts):\n",
        "#   sequences = tokenizer.texts_to_sequences(texts)\n",
        "#   padded = pad_sequences(sequences, truncating = 'post', padding='post', maxlen=50)\n",
        "#   return padded\n",
        "\n",
        "# padded_texts_train = get_sequences(tokenizer, texts_train) #pad texts_train\n",
        "\n",
        "# # create name_to_ids for intents\n",
        "# classes = sorted(set(intents_train))\n",
        "# #print(classes)\n",
        "# class_to_index = dict((c,i) for i, c in enumerate(classes))\n",
        "# index_to_class = dict((v,k) for k, v in class_to_index.items())\n",
        "# names_to_ids = lambda intents: np.array([class_to_index.get(x) for x in intents])\n",
        "# intents_train_ids = names_to_ids(intents_train) #name_to_ids intents_train\n",
        "# #print(index_to_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoKq9wYqxNSC"
      },
      "outputs": [],
      "source": [
        "# # creating model\n",
        "# model = tf.keras.models.Sequential([\n",
        "# tf.keras.layers.Embedding(10000,16,input_length=50),\n",
        "# tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences=True)),\n",
        "# tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n",
        "# tf.keras.layers.Dense(8, activation='softmax')\n",
        "# ])\n",
        "\n",
        "# model.compile(\n",
        "#      loss='sparse_categorical_crossentropy',\n",
        "#      optimizer='adam',\n",
        "#      metrics=['accuracy']\n",
        "# )\n",
        "\n",
        "\n",
        "# #define model learning rate\n",
        "# def learning_rate_schedule(epoch, lr):\n",
        "#     \"\"\"Decrease the learning rate after 10 epochs.\"\"\"\n",
        "#     if epoch < 5:\n",
        "#         return lr\n",
        "#     else:\n",
        "#         initial_lr = 0.005  # Starting learning rate\n",
        "#         drop = 0.5  # Reduce to half\n",
        "#         epochs_drop = 50.0  # Every 10 epochs\n",
        "#         lr = initial_lr * (drop ** tf.math.floor((1+epoch)/epochs_drop))\n",
        "#         return lr\n",
        "\n",
        "# lr_scheduler = tf.keras.callbacks.LearningRateScheduler(learning_rate_schedule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgNL5M7GS2cU",
        "outputId": "68ea6e64-3be9-4291-fc98-428cf7e47f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 11s 257ms/step - loss: 2.0715 - accuracy: 0.1504 - val_loss: 2.0471 - val_accuracy: 0.3642 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 1s 80ms/step - loss: 2.0456 - accuracy: 0.2058 - val_loss: 1.9882 - val_accuracy: 0.3311 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 1s 61ms/step - loss: 2.0208 - accuracy: 0.1991 - val_loss: 1.9370 - val_accuracy: 0.3311 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 1s 33ms/step - loss: 2.0098 - accuracy: 0.1991 - val_loss: 1.9356 - val_accuracy: 0.3311 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 1s 29ms/step - loss: 1.9818 - accuracy: 0.1991 - val_loss: 1.8830 - val_accuracy: 0.3311 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 20ms/step - loss: 1.7618 - accuracy: 0.3562 - val_loss: 1.6548 - val_accuracy: 0.2384 - lr: 0.0050\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 1.3294 - accuracy: 0.5022 - val_loss: 1.3946 - val_accuracy: 0.5629 - lr: 0.0050\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 0.9417 - accuracy: 0.7102 - val_loss: 1.1078 - val_accuracy: 0.5364 - lr: 0.0050\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 1s 51ms/step - loss: 0.5389 - accuracy: 0.8385 - val_loss: 0.8747 - val_accuracy: 0.7483 - lr: 0.0050\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 1s 40ms/step - loss: 0.3362 - accuracy: 0.8982 - val_loss: 0.8113 - val_accuracy: 0.7417 - lr: 0.0050\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 1s 52ms/step - loss: 0.1776 - accuracy: 0.9757 - val_loss: 0.8513 - val_accuracy: 0.7682 - lr: 0.0050\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 1s 42ms/step - loss: 0.1149 - accuracy: 0.9823 - val_loss: 0.8960 - val_accuracy: 0.6093 - lr: 0.0050\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 0.0720 - accuracy: 0.9867 - val_loss: 0.7997 - val_accuracy: 0.7748 - lr: 0.0050\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 0.0569 - accuracy: 0.9889 - val_loss: 0.9126 - val_accuracy: 0.7815 - lr: 0.0050\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 24ms/step - loss: 0.0579 - accuracy: 0.9889 - val_loss: 0.7969 - val_accuracy: 0.7815 - lr: 0.0050\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 25ms/step - loss: 0.0387 - accuracy: 0.9934 - val_loss: 0.8939 - val_accuracy: 0.7748 - lr: 0.0050\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.0252 - accuracy: 0.9956 - val_loss: 0.8985 - val_accuracy: 0.7815 - lr: 0.0050\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 20ms/step - loss: 0.0198 - accuracy: 0.9978 - val_loss: 0.7875 - val_accuracy: 0.8013 - lr: 0.0050\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 0.0165 - accuracy: 0.9978 - val_loss: 0.8201 - val_accuracy: 0.8146 - lr: 0.0050\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.0136 - accuracy: 0.9978 - val_loss: 0.8542 - val_accuracy: 0.8079 - lr: 0.0050\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.0118 - accuracy: 0.9978 - val_loss: 0.8593 - val_accuracy: 0.8212 - lr: 0.0050\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.0105 - accuracy: 0.9978 - val_loss: 0.8619 - val_accuracy: 0.8146 - lr: 0.0050\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.0100 - accuracy: 0.9978 - val_loss: 0.9373 - val_accuracy: 0.8079 - lr: 0.0050\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 1s 36ms/step - loss: 0.0115 - accuracy: 0.9978 - val_loss: 0.9468 - val_accuracy: 0.7815 - lr: 0.0050\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.0127 - accuracy: 0.9978 - val_loss: 0.8895 - val_accuracy: 0.8013 - lr: 0.0050\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.9672 - val_accuracy: 0.7881 - lr: 0.0050\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.9725 - val_accuracy: 0.7947 - lr: 0.0050\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 1s 37ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.9750 - val_accuracy: 0.8013 - lr: 0.0050\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 20ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.0693 - val_accuracy: 0.7682 - lr: 0.0050\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.0549 - val_accuracy: 0.7881 - lr: 0.0050\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.0972 - val_accuracy: 0.7748 - lr: 0.0050\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.0916 - val_accuracy: 0.7748 - lr: 0.0050\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1451 - val_accuracy: 0.7748 - lr: 0.0050\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.1759 - val_accuracy: 0.7748 - lr: 0.0050\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1816 - val_accuracy: 0.7748 - lr: 0.0050\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2052 - val_accuracy: 0.7682 - lr: 0.0050\n"
          ]
        }
      ],
      "source": [
        "# padded_texts_val = get_sequences(tokenizer, texts_val) #pad texts_val\n",
        "# intents_val_ids = names_to_ids(intents_val) #names_to_ids intents_val\n",
        "\n",
        "# #training model\n",
        "# h = model.fit(\n",
        "#      padded_texts_train, intents_train_ids, #padded/ids train data of texts, intents\n",
        "#      validation_data=(padded_texts_val, intents_val_ids), #padded/ids val data of texts, intents\n",
        "#      epochs=100,\n",
        "#      callbacks=[lr_scheduler, tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15)]\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Yj3P24qMe31",
        "outputId": "51ca2f2d-fa3b-4615-8260-d4ebf58123a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 8ms/step - loss: 1.3184 - accuracy: 0.7881\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3184443712234497, 0.7880794405937195]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# # evaluating model on test data\n",
        "# padded_texts_test = get_sequences(tokenizer, texts_test) #pad texts_test\n",
        "# intents_test_ids = names_to_ids(intents_test) #names_to_ids intents_test\n",
        "\n",
        "# model.evaluate(padded_texts_test, intents_test_ids) #padded/ids test data of texts, intents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDqbDczwOMAm",
        "outputId": "53038869-f34b-4226-e17b-7aa79be7759d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text: Play my favorite playlist.\n",
            "intent: music\n",
            "predicted_intent:  music\n"
          ]
        }
      ],
      "source": [
        "# # testing the model\n",
        "# i = random.randint(0,len(intents_test_ids)-1)\n",
        "# print('text:', texts_test[i])\n",
        "# print('intent:', index_to_class[intents_test_ids[i]])\n",
        "# p = model.predict(np.expand_dims(padded_texts_test[i], axis=0), verbose = 0)[0]\n",
        "# pred_class=index_to_class[np.argmax(p).astype('uint8')]\n",
        "# print('predicted_intent: ', pred_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40RZ9hyRVNtk"
      },
      "outputs": [],
      "source": [
        "# saving model to drive\n",
        "#model.save(\"/content/gdrive/MyDrive/Chatbot/CA1/Keras_model.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert test, train, val training_data to pandas DataFrame\n",
        "# train_df = pd.DataFrame({'texts': texts_train, 'intents': intents_train})\n",
        "# test_df = pd.DataFrame({'texts': texts_test, 'intents': intents_test})\n",
        "# val_df = pd.DataFrame({'texts': texts_val, 'intents': intents_val})\n",
        "\n",
        "# import os\n",
        "# save_path = \"/content/gdrive/MyDrive/Chatbot/CA1/\"\n",
        "# os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# # save DataFrame to csv files on drive\n",
        "# train_df.to_csv(save_path + 'train_df.csv', index=False)\n",
        "# test_df.to_csv(save_path + 'test_df.csv', index=False)\n",
        "# val_df.to_csv(save_path + 'val_df.csv', index=False)"
      ],
      "metadata": {
        "id": "UubA_tQCzcx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Main Chatbot Intent Recognizer - Keras LSTM (Load Saved Model from Here)**"
      ],
      "metadata": {
        "id": "ltacgj-uhy2D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5BrpR7BjT5G"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# loading saved model from drive\n",
        "model = tf.keras.models.load_model(save_path + \"Keras_model.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load saved training_data from drive\n",
        "train_df = pd.read_csv(save_path + \"train_df.csv\")\n",
        "test_df = pd.read_csv(save_path + \"test_df.csv\")\n",
        "val_df = pd.read_csv(save_path + \"val_df.csv\")\n",
        "\n",
        "#obtain saved texts, intents datasets\n",
        "texts_train = train_df['texts'].tolist()\n",
        "intents_train = train_df['intents'].tolist()\n",
        "\n",
        "texts_test = test_df['texts'].tolist()\n",
        "intents_test = test_df['intents'].tolist()\n",
        "\n",
        "texts_val = val_df['texts'].tolist()\n",
        "intents_val = val_df['intents'].tolist()\n",
        "\n",
        "#fit tokenizer on loaded texts_train data to be used in our main chatbot code\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token='<UNK>')\n",
        "tokenizer.fit_on_texts(texts_train)\n",
        "\n",
        "def get_sequences(tokenizer, texts):\n",
        "  sequences = tokenizer.texts_to_sequences(texts)\n",
        "  padded = pad_sequences(sequences, truncating = 'post', padding='post', maxlen=50)\n",
        "  return padded\n",
        "\n",
        "padded_texts_train = get_sequences(tokenizer, texts_train) #pad texts_train\n",
        "\n",
        "# load back functions\n",
        "# create name_to_ids for intents\n",
        "classes = sorted(set(intents_train))\n",
        "#print(classes)\n",
        "class_to_index = dict((c,i) for i, c in enumerate(classes))\n",
        "index_to_class = dict((v,k) for k, v in class_to_index.items())\n",
        "names_to_ids = lambda intents: np.array([class_to_index.get(x) for x in intents])\n",
        "intents_train_ids = names_to_ids(intents_train) #name_to_ids intents_train\n",
        "#print(index_to_class)"
      ],
      "metadata": {
        "id": "xEJgpdxT5-sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing saved model\n",
        "# evaluating model on test data\n",
        "\n",
        "padded_texts_test = get_sequences(tokenizer, texts_test) #pad texts_test\n",
        "intents_test_ids = names_to_ids(intents_test) #names_to_ids intents_test\n",
        "print(model.summary())\n",
        "model.evaluate(padded_texts_test, intents_test_ids) #padded/ids test data of texts, intents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK_YvUPkKk-1",
        "outputId": "a9be369a-7637-44c2-d280-b01dd4d60f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 50, 16)            160000    \n",
            "                                                                 \n",
            " bidirectional_8 (Bidirecti  (None, 50, 40)            5920      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_9 (Bidirecti  (None, 40)                9760      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 8)                 328       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 176008 (687.53 KB)\n",
            "Trainable params: 176008 (687.53 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "5/5 [==============================] - 3s 11ms/step - loss: 1.3184 - accuracy: 0.7881\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3184443712234497, 0.7880794405937195]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oax2K7b9rwq6"
      },
      "source": [
        "## **Weather App - sklearn MLP Classifier, Weather API**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwHJKhRWkCPY"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "import requests # HTTP requests (GET / POST)\n",
        "import datetime\n",
        "import pandas as pd\n",
        "from IPython.display import display, Image\n",
        "import folium\n",
        "import json\n",
        "\n",
        "# Load and preprocess weather training data\n",
        "weather_training_data = [ ('temperature', 'Singapore'),\n",
        "  ('temperature in ang mo kio', 'Ang Mo Kio'),  ('temperature in amk', 'Ang Mo Kio'), ('temperature in bedok', 'Bedok'),  ('temperature in bishan', 'Bishan'), ('temperature in boon lay', 'Boon Lay'), ('temperature in bukit batok', 'Bukit Batok'), ('temperature in bukit merah', 'Bukit Merah'),\n",
        " ('temperature in bukit panjang', 'Bukit Panjang'), ('temperature in bukit timah', 'Bukit Timah'), ('temperature in central water catchment', 'Central Water Catchment'), ('temperature in changi', 'Changi'), ('temperature in choa chu kang', 'Choa Chu Kang'),\n",
        " ('temperature in clementi', 'Clementi'), ('temperature in city', 'City'), ('temperature in geylang', 'Geylang'), ('temperature in hougang', 'Hougang'), ('temperature in jalan bahar', 'Jalan Bahar'), ('temperature in jurong east', 'Jurong East'),\n",
        " ('temperature in jurong island', 'Jurong Island'), ('temperature in jurong west', 'Jurong West'), ('temperature in kallang', 'Kallang'), ('temperature in lim chu kang', 'Lim Chu Kang'), ('temperature in mandai', 'Mandai'), ('temperature in marine parade', 'Marine Parade'),\n",
        " ('temperature in novena', 'Novena'), ('temperature in pasir ris', 'Pasir Ris'), ('temperature in paya lebar', 'Paya Lebar'), ('temperature in pioneer', 'Pioneer'), ('temperature in pulau tekong', 'Pulau Tekong'), ('temperature in pulau ubin', 'Pulau Ubin'),\n",
        " ('temperature in punggol', 'Punggol'), ('temperature in queenstown', 'Queenstown'), ('temperature in seletar', 'Seletar'), ('temperature in sembawang', 'Sembawang'), ('temperature in sengkang', 'Sengkang'), ('temperature in sentosa', 'Sentosa'),\n",
        " ('temperature in serangoon', 'Serangoon'), ('temperature in southern islands', 'Southern Islands'), ('temperature in sungei kadut', 'Sungei Kadut'), ('temperature in tampines', 'Tampines'), ('temperature in tanglin', 'Tanglin'), ('temperature in tengah', 'Tengah'),\n",
        " ('temperature in toa payoh', 'Toa Payoh'), ('temperature in tuas', 'Tuas'), ('temperature in western islands', 'Western Islands'), ('temperature in western water catchment', 'Western Water Catchment'), ('temperature in woodlands', 'Woodlands'),\n",
        " ('temperature in yishun', 'Yishun'), ('temperature in singapore', 'Singapore'),\n",
        " ('weather', 'Singapore'),\n",
        " ('weather in ang mo kio', 'Ang Mo Kio'), ('weather in bedok', 'Bedok'), ('weather in bishan', 'Bishan'), ('weather in boon lay', 'Boon Lay'), ('weather in bukit batok', 'Bukit Batok'), ('weather in bukit merah', 'Bukit Merah'),\n",
        " ('weather in bukit panjang', 'Bukit Panjang'), ('weather in bukit timah', 'Bukit Timah'), ('weather in central water catchment', 'Central Water Catchment'), ('weather in changi', 'Changi'), ('weather in choa chu kang', 'Choa Chu Kang'),\n",
        " ('weather in clementi', 'Clementi'), ('weather in city', 'City'), ('weather in geylang', 'Geylang'), ('weather in hougang', 'Hougang'), ('weather in jalan bahar', 'Jalan Bahar'), ('weather in jurong east', 'Jurong East'),\n",
        " ('weather in jurong island', 'Jurong Island'), ('weather in jurong west', 'Jurong West'), ('weather in kallang', 'Kallang'), ('weather in lim chu kang', 'Lim Chu Kang'), ('weather in mandai', 'Mandai'), ('weather in marine parade', 'Marine Parade'),\n",
        " ('weather in novena', 'Novena'), ('weather in pasir ris', 'Pasir Ris'), ('weather in paya lebar', 'Paya Lebar'), ('weather in pioneer', 'Pioneer'), ('weather in pulau tekong', 'Pulau Tekong'), ('weather in pulau ubin', 'Pulau Ubin'), ('weather in punggol', 'Punggol'),\n",
        " ('weather in queenstown', 'Queenstown'), ('weather in seletar', 'Seletar'), ('weather in sembawang', 'Sembawang'), ('weather in sengkang', 'Sengkang'), ('weather in sentosa', 'Sentosa'), ('weather setosa', 'Sentosa'), ('weather in serangoon', 'Serangoon'),\n",
        " ('weather in southern islands', 'Southern Islands'), ('weather in sungei kadut', 'Sungei Kadut'), ('weather in tampines', 'Tampines'), ('weather in tanglin', 'Tanglin'), ('weather in tengah', 'Tengah'),\n",
        " ('weather in toa payoh', 'Toa Payoh'), ('weather in tuas', 'Tuas'), ('weather in western islands', 'Western Islands'), ('weather in western water catchment', 'Western Water Catchment'), ('weather in woodlands', 'Woodlands'),\n",
        " ('weather in yishun', 'Yishun'), ('weather in singapore', 'Singapore')\n",
        " ]\n",
        "\n",
        "# Separate the data into text and location labels\n",
        "weather_texts, weather_locations = zip(*weather_training_data)\n",
        "\n",
        "# Create a simple pipeline with CountVectorizer and MLPClassifier for intent classification\n",
        "weather_intent_classifier = make_pipeline(CountVectorizer(), MLPClassifier(random_state=1, max_iter=1000))\n",
        "weather_intent_classifier.fit(weather_texts, weather_locations)\n",
        "\n",
        "def weather_location_input(user_input):\n",
        "\n",
        "    doc = nlp(user_input)\n",
        "\n",
        "    # Use the weather intent classifier to predict the intent with user_input\n",
        "    predicted_location = weather_intent_classifier.predict([user_input])[0]\n",
        "\n",
        "    if predicted_location in weather_locations_list:\n",
        "\n",
        "        #print(\"predicted_weather_location: \", predicted_location)\n",
        "\n",
        "        location_temperature_input = weather_locations_list[predicted_location][0]\n",
        "        location_weather_input = weather_locations_list[predicted_location][1]\n",
        "        location_particulate_input = weather_locations_list[predicted_location][2]\n",
        "\n",
        "        return predicted_location, location_temperature_input, location_weather_input, location_particulate_input\n",
        "\n",
        "    else:\n",
        "        # If no explicit intent is found, use the conversation state to generate a response\n",
        "        print(\"Chatbot: I am sorry, may you rephrase your weather location question please?\")\n",
        "\n",
        "#Define weather_locations_list dictionary with values for location temperature, location weather, location particulate matter\n",
        "weather_locations_list = {\"Ang Mo Kio\" : [\"Kim Chuan Road\", \"Ang Mo Kio\" , 2],\n",
        "                          \"Bedok\" : [\"Kim Chuan Road\", \"Bedok\" , 1],\n",
        "                          \"Bishan\" : [\"Kim Chuan Road\", \"Bishan\" , 2],\n",
        "                          \"Boon Lay\" : [\"Kim Chuan Road\", \"Boon Lay\" , 0],\n",
        "                          \"Bukit Batok\" : [\"Tuas South Avenue 3\", \"Bukit Batok\" , 0],\n",
        "                          \"Bukit Merah\" : [\"Kim Chuan Road\", \"Bukit Merah\" , 3],\n",
        "                          \"Bukit Panjang\" : [\"Tuas South Avenue 3\", \"Bukit Panjang\" , 2],\n",
        "                          \"Bukit Timah\" : [\"Scotts Road\", \"Bukit Timah\" , 2],\n",
        "                          \"Water Catchment\" : [\"Kim Chuan Road\", \"Water Catchment\" , 2],\n",
        "                          \"Changi\" : [\"Kim Chuan Road\", \"Changi\" , 1],\n",
        "                          \"Choa Chu Kang\" : [\"Tuas South Avenue 3\", \"Choa Chu Kang\" , 0],\n",
        "                          \"Clementi\" : [\"Clementi Road\", \"Clementi\" , 0],\n",
        "                          \"City\" : [\"Scotts Road\", \"City\" , 3],\n",
        "                          \"Geylang\" : [\"Kim Chuan Road\", \"Geylang\" , 1],\n",
        "                          \"Hougang\" : [\"Kim Chuan Road\", \"Hougang\" , 2],\n",
        "                          \"Jalan Bahar\" : [\"Tuas South Avenue 3\", \"Jalan Bahar\" , 0],\n",
        "                          \"Jurong East\" : [\"Clementi Road\", \"Jurong East\" , 0],\n",
        "                          \"Jurong Island\" : [\"Banyan Road\", \"Jurong Island\" , 0],\n",
        "                          \"Jurong West\" : [\"Tuas South Avenue 3\", \"Jurong West\" , 0],\n",
        "                          \"Kallang\" : [\"Kim Chuan Road\", \"Kallang\" , 1],\n",
        "                          \"Lim Chu Kang\" : [\"Tuas South Avenue 3\", \"Lim Chu Kang\" , 0],\n",
        "                          \"Mandai\" : [\"Scotts Road\", \"Mandai\" , 0],\n",
        "                          \"Marine Parade\" : [\"Kim Chuan Road\", \"Marine Parade\" , 1],\n",
        "                          \"Novena\" : [\"Kim Chuan Road\", \"Novena\" , 2],\n",
        "                          \"Pasir Ris\" : [\"Kim Chuan Road\", \"Pasir Ris\" , 2],\n",
        "                          \"Paya Lebar\" : [\"Kim Chuan Road\", \"Paya Lebar\" , 1],\n",
        "                          \"Pioneer\" : [\"Tuas South Avenue 3\", \"Pioneer\" , 0],\n",
        "                          \"Pulau Tekong\" : [\"Kim Chuan Road\", \"Pulau Tekong\" , 2],\n",
        "                          \"Pulau Ubin\" : [\"Kim Chuan Road\", \"Pulau Ubin\" , 2],\n",
        "                          \"Punggol\" : [\"Kim Chuan Road\", \"Punggol\" , 2],\n",
        "                          \"Queenstown\" : [\"Sentosa\", \"Queenstown\" , 2],\n",
        "                          \"Seletar\" : [\"Scotts Road\", \"Seletar\" , 4],\n",
        "                          \"Sembawang\" : [\"Scotts Road\", \"Sembawang\" , 4],\n",
        "                          \"Sengkang\" : [\"Kim Chuan Road\", \"Sengkang\" , 2],\n",
        "                          \"Sentosa\" : [\"Sentosa\", \"Sentosa\" , 3],\n",
        "                          \"Serangoon\" : [\"Kim Chuan Road\", \"Serangoon\" , 2],\n",
        "                          \"Southern Islands\" : [\"Sentosa\", \"Southern Islands\" , 2],\n",
        "                          \"Sungei Kadut\" : [\"Scotts Road\", \"Sungei Kadut\" , 4],\n",
        "                          \"Tampines\" : [\"Kim Chuan Road\", \"Tampines\" , 2],\n",
        "                          \"Tanglin\" : [\"Scotts Road\", \"Tanglin\" , 3],\n",
        "                          \"Tengah\" : [\"Tuas South Avenue 3\", \"Tengah\" , 0],\n",
        "                          \"Toa Payoh\" : [\"Kim Chuan Road\", \"Toa Payoh\" , 2],\n",
        "                          \"Tuas\" : [\"Tuas South Avenue 3\", \"Tuas\" , 0],\n",
        "                          \"Western Islands\" : [\"Banyan Road\", \"Western Islands\" , 0],\n",
        "                          \"Western Water Catchment\" : [\"Tuas South Avenue 3\", \"Western Water Catchment\" , 0],\n",
        "                          \"Woodlands\" : [\"Scotts Road\", \"Woodlands\" , 4],\n",
        "                          \"Yishun\" : [\"Scotts Road\", \"Yishun\" , 4],\n",
        "                          \"Singapore\" : [\"Kim Chuan Road\", \"Ang Mo Kio\" , 2],\n",
        "                     }\n",
        "\n",
        "\n",
        "def weatherapp(user_input):\n",
        "\n",
        "    #get predicted location, location temperature, weather and particulate info using weather_location_input\n",
        "    predicted_location, location_temperature_input, location_weather_input, location_particulate_input = weather_location_input(user_input)\n",
        "\n",
        "    #print(predicted_location, location_temperature_input, location_weather_input, location_particulate_input)\n",
        "\n",
        "    # Obtaining temperature data - weather locations change periodically, if there is error, monitor the temperature API locations\n",
        "    today = datetime.datetime.today()\n",
        "    params = {\"date_time\": today.strftime(\"%Y-%m-%dT%H:%M:%S\")} # YYYY-MM-DD\n",
        "    wx = requests.get('https://api.data.gov.sg/v1/environment/air-temperature', params=params).json()\n",
        "\n",
        "    tempDf = pd.DataFrame(wx['metadata']['stations']).merge(pd.DataFrame(wx['items'][0]['readings']), left_on='id', right_on='station_id', how='inner')\n",
        "    tempDf = tempDf[[\"name\", \"value\"]]\n",
        "    tempDf.columns = ['Name', 'Temperature']\n",
        "    #print(tempDf)\n",
        "    temperature = tempDf.loc[tempDf['Name'] == location_temperature_input, 'Temperature'].iloc[0]\n",
        "\n",
        "    # 2-hour weather forecast data\n",
        "    today = datetime.datetime.today()\n",
        "    params = {\"date\": today.strftime(\"%Y-%m-%d\")} # YYYY-MM-DD\n",
        "    wx_forecast = requests.get('https://api.data.gov.sg/v1/environment/2-hour-weather-forecast', params=params).json()\n",
        "\n",
        "\n",
        "    plotDf = pd.DataFrame(wx_forecast['area_metadata']).merge(pd.DataFrame(wx_forecast['items'][-1]['forecasts']).reset_index(), how='inner', left_on='name', right_on='area')\n",
        "    plotDf = plotDf[['area','forecast']]\n",
        "    #print(plotDf)\n",
        "    weather = plotDf.loc[plotDf['area'] == location_weather_input, 'forecast'].iloc[0].replace(\"(Day)\",\"\")\n",
        "    weather = weather.replace(\"(Night)\",\"\")\n",
        "    weather = weather.lower()\n",
        "\n",
        "    # Obtaining particulate data\n",
        "    today = datetime.datetime.today()\n",
        "    params = {\"date\": today.strftime(\"%Y-%m-%d\")} # YYYY-MM-DD\n",
        "    #psi = requests.get('https://api.data.gov.sg/v1/environment/psi', params=params).json() #issue with obtaining current psi with date\n",
        "    psi = requests.get('https://api.data.gov.sg/v1/environment/psi').json() #still returns current daily psi readings\n",
        "\n",
        "    # Showing latest particulate in a dataframe\n",
        "    psiDf = pd.DataFrame(psi['items'][0]['readings'])\n",
        "    #print(psiDf)\n",
        "    psi = psiDf.iloc[location_particulate_input][10] #PSI is 10th particulate info\n",
        "\n",
        "    # Obtaining UVI data\n",
        "    today = datetime.datetime.today()\n",
        "    params = {\"date\": today.strftime(\"%Y-%m-%d\")} # YYYY-MM-DD\n",
        "    uv = requests.get('https://api.data.gov.sg/v1/environment/uv-index', params=params).json()\n",
        "    uv_status = uv[\"api_info\"][\"status\"]\n",
        "\n",
        "    #weather chatbot response\n",
        "    print(\"Chatbot: The weather in\", predicted_location, \"is currently\", weather, \"with a temperature of\", temperature, \"°C. PSI is\", psi, \"and UV status is\", uv_status, \".\")\n",
        "    print(\"Chatbot: Will you be going out? Please answer yes or no.\")\n",
        "\n",
        "    while True:\n",
        "        user1_input = input(\"You: \")\n",
        "\n",
        "        if user1_input.lower() == 'yes':\n",
        "\n",
        "            print(\"Chatbot: Do have a great time then!\")\n",
        "\n",
        "            if weather == \"Showers\":\n",
        "                print(\"Chatbot: Remember to bring out an umbrella!\")\n",
        "                print(\"Chatbot: Is there anything else I can help with?\")\n",
        "\n",
        "            elif temperature > 30:\n",
        "                print(\"Chatbot: It is a warm day, so please take care!\")\n",
        "                print(\"Chatbot: Is there anything else I can help with?\")\n",
        "\n",
        "            elif temperature < 25:\n",
        "                print(\"Chatbot: It is a chilly day, please don't catch a cold!\")\n",
        "                print(\"Chatbot: Is there anything else I can help with?\")\n",
        "\n",
        "            elif uv_status != \"healthy\":\n",
        "                print(\"Chatbot: Please put some sunscreen before going out!\")\n",
        "                print(\"Chatbot: Is there anything else I can help with?\")\n",
        "\n",
        "            else:\n",
        "                print(\"Chatbot: Is there anything else I can help with?\")\n",
        "\n",
        "            break\n",
        "\n",
        "        elif user1_input.lower() == 'no':\n",
        "\n",
        "            print(\"Chatbot: Yes, staying at home would be better!\")\n",
        "\n",
        "            if weather == \"Showers\":\n",
        "                print(\"Chatbot: It is raining outside, remember to close your windows!\")\n",
        "                print(\"Chatbot: Is there anything else I can help with?\")\n",
        "\n",
        "            elif temperature > 30:\n",
        "                print(\"Chatbot: It is currently warm outside, turning on the Air Conditioner would be great!\")\n",
        "                print(\"Chatbot: Is there anything else I can help with?\")\n",
        "\n",
        "            elif temperature < 25:\n",
        "                print(\"Chatbot: It is chilly now, I would suggest curling up in bed and reading a book!\")\n",
        "\n",
        "            else:\n",
        "                print(\"Chatbot: Is there anything else I can help with?\")\n",
        "\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"Chatbot: Sorry, only yes or no answers allowed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOGdxDZx-pBu"
      },
      "source": [
        "## **Music App - Spotify API**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6j-xcb1E4IY3"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from IPython.display import IFrame\n",
        "import random\n",
        "\n",
        "# Getting client details from Spotify account\n",
        "client_id = \"96e245a13d3542f69cfd637c11ea7e21\",\n",
        "client_secret = \"b42efd96d9ee49ffb3e584b9bfdfb13d\"\n",
        "\n",
        "# spotify_access_token function\n",
        "def get_spotify_access_token(client_id, client_secret):\n",
        "    auth_url = 'https://accounts.spotify.com/api/token'\n",
        "    auth_response = requests.post(auth_url, {\n",
        "        'grant_type': 'client_credentials',\n",
        "        'client_id': client_id,\n",
        "        'client_secret': client_secret,\n",
        "    })\n",
        "    auth_response_data = auth_response.json()\n",
        "    return auth_response_data['access_token']\n",
        "\n",
        "# embedded playlist tracks function\n",
        "def get_playlist_tracks_embedded(playlist_id, access_token):\n",
        "    base_url = 'https://api.spotify.com/v1/playlists/'\n",
        "    headers = {\n",
        "        'Authorization': f'Bearer {access_token}',\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "    response = requests.get(f\"{base_url}{playlist_id}\", headers=headers)\n",
        "    playlist_data = response.json()\n",
        "\n",
        "    # Construct embeddable links using track IDs, including the utm_source query parameter\n",
        "    embedded_track_urls = [\n",
        "        track['track']['external_urls']['spotify'].replace(\"open.spotify.com/track\", \"open.spotify.com/embed/track\") + \"?utm_source=generator\"\n",
        "        for track in playlist_data['tracks']['items']\n",
        "    ]\n",
        "\n",
        "    return embedded_track_urls\n",
        "\n",
        "\n",
        "access_token = get_spotify_access_token(client_id, client_secret)\n",
        "\n",
        "#list of playlists\n",
        "chinese_playlist_token = \"2MmH2br9qJhRvCizQiIEU0\"\n",
        "english_playlist_token = \"37i9dQZF1EQncLwOalG3K7\"\n",
        "kpop_playlist_token = \"37i9dQZF1DX9tPFwDMOaN1\"\n",
        "\n",
        "#create playlists\n",
        "chinese_song_list = get_playlist_tracks_embedded(chinese_playlist_token, access_token)\n",
        "english_song_list = get_playlist_tracks_embedded(english_playlist_token, access_token)\n",
        "kpop_song_list = get_playlist_tracks_embedded(kpop_playlist_token, access_token)\n",
        "\n",
        "#music app\n",
        "def musicapp(user_intent):\n",
        "    print(\"Chatbot: What kind of music do you want to listen to? Chinese, English, or Kpop?\")\n",
        "    while True:\n",
        "        user2_input = input(\"You: \")\n",
        "\n",
        "        if user2_input.lower() == 'english':\n",
        "            print(\"Chatbot: Here are some English songs.\")\n",
        "            selected_songs = random.sample(english_song_list, 5)  # Randomly select 5 songs\n",
        "        elif user2_input.lower() == 'chinese':\n",
        "            print(\"Chatbot: Here are some Chinese songs.\")\n",
        "            selected_songs = random.sample(chinese_song_list, 5)  # Randomly select 5 songs\n",
        "        elif user2_input.lower() == 'kpop':\n",
        "            print(\"Chatbot: Here are some Kpop songs.\")\n",
        "            selected_songs = random.sample(kpop_song_list, 5)  # Randomly select 5 songs\n",
        "        else:\n",
        "            print(\"Chatbot: Please type 'English', 'Chinese' or 'Kpop' to select the song language.\")\n",
        "            continue\n",
        "\n",
        "        # Display the selected songs\n",
        "        for song_url in selected_songs:\n",
        "            display(IFrame(src=song_url, width=300, height=80))\n",
        "\n",
        "        print(\"Chatbot: Other than music, is there anything else I can help with?\")\n",
        "\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loWS8S0_bD9v"
      },
      "source": [
        "## **Kitchen App - Spacy Matcher**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5p68iVhfbHIy"
      },
      "outputs": [],
      "source": [
        "from spacy.matcher import Matcher\n",
        "from spacy import displacy\n",
        "\n",
        "# Initialize the Matcher with the spaCy vocabulary\n",
        "matcher_kitchen = Matcher(nlp.vocab)\n",
        "\n",
        "# Define patterns for items and locations we're interested in\n",
        "item_patterns = [\n",
        "    #drinks\n",
        "    [{\"LOWER\": \"soft\"}, {\"LOWER\": \"drink\"}],  # Match \"soft drink\" as a single item\n",
        "    [{\"LOWER\": \"can\"}],\n",
        "    [{\"LOWER\": \"water\"}],\n",
        "    [{\"LOWER\": \"coke\"}],\n",
        "    [{\"LOWER\": \"coca\"}, {\"LOWER\": \"cola\"}],\n",
        "    [{\"LOWER\": \"pepsi\"}],\n",
        "    [{\"LOWER\": \"dr\"}, {\"LOWER\": \"pepper\"}],\n",
        "    [{\"LOWER\": \"mountain\"}, {\"LOWER\": \"dew\"}],\n",
        "    [{\"LOWER\": \"sprite\"}],\n",
        "    [{\"LOWER\": \"beer\"}],\n",
        "    [{\"LOWER\": \"coffee\"}],\n",
        "    [{\"LOWER\": \"tea\"}],\n",
        "    [{\"LOWER\": \"juice\"}],\n",
        "    [{\"LOWER\": \"milk\"}],\n",
        "    [{\"LOWER\": \"tea\"}],\n",
        "    [{\"LOWER\": \"latte\"}],\n",
        "    [{\"LOWER\": \"chocolate\"}],\n",
        "    [{\"LOWER\": \"smoothie\"}],\n",
        "    [{\"LOWER\": \"milkshake\"}],\n",
        "    [{\"LOWER\": \"wine\"}],\n",
        "    [{\"LOWER\": \"vodka\"}],\n",
        "    [{\"LOWER\": \"rum\"}],\n",
        "    [{\"LOWER\": \"whiskey\"}],\n",
        "    [{\"LOWER\": \"kombucha\"}],\n",
        "    [{\"LOWER\": \"matcha\"}],\n",
        "    [{\"LOWER\": \"herbal\"}, {\"LOWER\": \"tea\"}],\n",
        "    [{\"LOWER\": \"espresso\"}],\n",
        "    [{\"LOWER\": \"cappaccino\"}],\n",
        "    [{\"LOWER\": \"americano\"}],\n",
        "    [{\"LOWER\": \"gin\"}],\n",
        "    [{\"LOWER\": \"tequila\"}],\n",
        "    [{\"LOWER\": \"mojito\"}],\n",
        "    [{\"LOWER\": \"sangria\"}],\n",
        "    [{\"LOWER\": \"champagne\"}],\n",
        "    [{\"LOWER\": \"martini\"}],\n",
        "    [{\"LOWER\": \"prosecco\"}],\n",
        "\n",
        "    #fruits\n",
        "    [{\"LOWER\": \"lychee\"}],\n",
        "    [{\"LOWER\": \"dragonfruit\"}],\n",
        "    [{\"LOWER\": \"apple\"}],\n",
        "    [{\"LOWER\": \"pear\"}],\n",
        "    [{\"LOWER\": \"kiwi\"}],\n",
        "    [{\"LOWER\": \"guava\"}],\n",
        "    [{\"LOWER\": \"pineapple\"}],\n",
        "    [{\"LOWER\": \"banana\"}],\n",
        "    [{\"LOWER\": \"orange\"}],\n",
        "    [{\"LOWER\": \"mango\"}],\n",
        "    [{\"LOWER\": \"watermelon\"}],\n",
        "    [{\"LOWER\": \"jackfruit\"}],\n",
        "    [{\"LOWER\": \"durian\"}],\n",
        "    [{\"LOWER\": \"strawberry\"}],\n",
        "    [{\"LOWER\": \"blueberry\"}],\n",
        "    [{\"LOWER\": \"lemon\"}],\n",
        "    [{\"LOWER\": \"lime\"}],\n",
        "    [{\"LOWER\": \"coconut\"}],\n",
        "    [{\"LOWER\": \"fig\"}],\n",
        "    [{\"LOWER\": \"pomegranate\"}],\n",
        "    [{\"LOWER\": \"kiwi\"}],\n",
        "    [{\"LOWER\": \"apricot\"}],\n",
        "    [{\"LOWER\": \"nectarine\"}],\n",
        "    [{\"LOWER\": \"grapefruit\"}],\n",
        "    [{\"LOWER\": \"avocado\"}],\n",
        "    [{\"LOWER\": \"cantaloupe\"}],\n",
        "    [{\"LOWER\": \"honeydew\"}],\n",
        "    [{\"LOWER\": \"soursop\"}],\n",
        "    [{\"LOWER\": \"raspberry\"}],\n",
        "    [{\"LOWER\": \"pomegranate\"}],\n",
        "    [{\"LOWER\": \"apricot\"}],\n",
        "    [{\"LOWER\": \"plum\"}],\n",
        "    [{\"LOWER\": \"tangerine\"}],\n",
        "    [{\"LOWER\": \"fig\"}],\n",
        "    [{\"LOWER\": \"gooseberry\"}],\n",
        "    [{\"LOWER\": \"olive\"}],\n",
        "\n",
        "    #vegetables\n",
        "    [{\"LOWER\": \"cucumber\"}],\n",
        "    [{\"LOWER\": \"tomato\"}],\n",
        "    [{\"LOWER\": \"potato\"}],\n",
        "    [{\"LOWER\": \"onion\"}],\n",
        "    [{\"LOWER\": \"garlic\"}],\n",
        "    [{\"LOWER\": \"carrot\"}],\n",
        "    [{\"LOWER\": \"celery\"}],\n",
        "    [{\"LOWER\": \"lettuce\"}],\n",
        "    [{\"LOWER\": \"spinach\"}],\n",
        "    [{\"LOWER\": \"kale\"}],\n",
        "    [{\"LOWER\": \"cabbage\"}],\n",
        "    [{\"LOWER\": \"broccoli\"}],\n",
        "    [{\"LOWER\": \"cauliflower\"}],\n",
        "    [{\"LOWER\": \"bell pepper\"}],\n",
        "    [{\"LOWER\": \"chili pepper\"}],\n",
        "    [{\"LOWER\": \"zucchini\"}],\n",
        "    [{\"LOWER\": \"eggplant\"}],\n",
        "    [{\"LOWER\": \"squash\"}],\n",
        "    [{\"LOWER\": \"sweet potato\"}],\n",
        "    [{\"LOWER\": \"corn\"}],\n",
        "    [{\"LOWER\": \"peas\"}],\n",
        "    [{\"LOWER\": \"beans\"}],\n",
        "    [{\"LOWER\": \"lentils\"}],\n",
        "\n",
        "    #condiments\n",
        "    [{\"LOWER\": \"sugar\"}],\n",
        "    [{\"LOWER\": \"salt\"}],\n",
        "    [{\"LOWER\": \"pepper\"}],\n",
        "    [{\"LOWER\": \"cinnamon\"}],\n",
        "    [{\"LOWER\": \"nutmeg\"}],\n",
        "    [{\"LOWER\": \"vanilla\"}],\n",
        "    [{\"LOWER\": \"olive oil\"}],\n",
        "    [{\"LOWER\": \"vegetable oil\"}],\n",
        "    [{\"LOWER\": \"jam\"}],\n",
        "    [{\"LOWER\": \"honey\"}],\n",
        "    [{\"LOWER\": \"syrup\"}],\n",
        "    [{\"LOWER\": \"vinegar\"}],\n",
        "    [{\"LOWER\": \"soy sauce\"}],\n",
        "    [{\"LOWER\": \"ketchup\"}],\n",
        "    [{\"LOWER\": \"mustard\"}],\n",
        "    [{\"LOWER\": \"mayonnaise\"}],\n",
        "    [{\"LOWER\": \"pickle\"}],\n",
        "    [{\"LOWER\": \"relish\"}],\n",
        "    [{\"LOWER\": \"salsa\"}],\n",
        "    [{\"LOWER\": \"guacamole\"}],\n",
        "    [{\"LOWER\": \"hummus\"}],\n",
        "    [{\"LOWER\": \"peanut butter\"}],\n",
        "\n",
        "    #dairy\n",
        "    [{\"LOWER\": \"butter\"}],\n",
        "    [{\"LOWER\": \"milk\"}],\n",
        "    [{\"LOWER\": \"cream\"}],\n",
        "    [{\"LOWER\": \"cheese\"}],\n",
        "    [{\"LOWER\": \"yogurt\"}],\n",
        "    [{\"LOWER\": \"eggs\"}],\n",
        "\n",
        "    #foods\n",
        "    [{\"LOWER\": \"rice\"}],\n",
        "    [{\"LOWER\": \"pasta\"}],\n",
        "    [{\"LOWER\": \"quinoa\"}],\n",
        "    [{\"LOWER\": \"oats\"}],\n",
        "    [{\"LOWER\": \"flour\"}],\n",
        "    [{\"LOWER\": \"bread\"}],\n",
        "    [{\"LOWER\": \"bagel\"}],\n",
        "    [{\"LOWER\": \"tortilla\"}],\n",
        "    [{\"LOWER\": \"pancake\"}],\n",
        "    [{\"LOWER\": \"waffle\"}],\n",
        "    [{\"LOWER\": \"croissant\"}],\n",
        "    [{\"LOWER\": \"muffin\"}],\n",
        "    [{\"LOWER\": \"cake\"}],\n",
        "    [{\"LOWER\": \"cookie\"}],\n",
        "    [{\"LOWER\": \"brownie\"}],\n",
        "    [{\"LOWER\": \"pie\"}],\n",
        "    [{\"LOWER\": \"pudding\"}],\n",
        "    [{\"LOWER\": \"ice cream\"}],\n",
        "    [{\"LOWER\": \"chocolate\"}],\n",
        "    [{\"LOWER\": \"jelly\"}],\n",
        "\n",
        "]\n",
        "\n",
        "location_patterns = [\n",
        "    [{\"LOWER\": \"refrigerator\"}],\n",
        "    [{\"LOWER\": \"fridge\"}],\n",
        "    [{\"LOWER\": \"kitchen\"}],\n",
        "    [{\"LOWER\": \"pantry\"}],\n",
        "    [{\"LOWER\": \"cabinet\"}],\n",
        "    [{\"LOWER\": \"drawer\"}],\n",
        "    [{\"LOWER\": \"shelf\"}],\n",
        "    [{\"LOWER\": \"counter\"}],\n",
        "    [{\"LOWER\": \"cupboard\"}],\n",
        "    [{\"LOWER\": \"freezer\"}],\n",
        "    [{\"LOWER\": \"icebox\"}],\n",
        "    [{\"LOWER\": \"vegetable bin\"}],\n",
        "    [{\"LOWER\": \"fruit basket\"}],\n",
        "    [{\"LOWER\": \"spice rack\"}],\n",
        "    [{\"LOWER\": \"wine rack\"}],\n",
        "    [{\"LOWER\": \"rack\"}],\n",
        "    [{\"LOWER\": \"dish rack\"}],\n",
        "    [{\"LOWER\": \"utensil holder\"}],\n",
        "    [{\"LOWER\": \"knife block\"}],\n",
        "    [{\"LOWER\": \"towel rack\"}],\n",
        "    [{\"LOWER\": \"pot rack\"}],\n",
        "    [{\"LOWER\": \"hanging rack\"}],\n",
        "    [{\"LOWER\": \"breadbox\"}],\n",
        "    [{\"LOWER\": \"cookie jar\"}],\n",
        "    [{\"LOWER\": \"canister\"}],\n",
        "    [{\"LOWER\": \"jar\"}],\n",
        "    [{\"LOWER\": \"container\"}],\n",
        "    [{\"LOWER\": \"bin\"}],\n",
        "    [{\"LOWER\": \"basket\"}],\n",
        "    [{\"LOWER\": \"tray\"}],\n",
        "    [{\"LOWER\": \"tupperware\"}],\n",
        "    [{\"LOWER\": \"glassware cabinet\"}],\n",
        "    [{\"LOWER\": \"stemware rack\"}],\n",
        "    [{\"LOWER\": \"bottle rack\"}]\n",
        "]\n",
        "\n",
        "# Add patterns to the matcher\n",
        "for pattern in item_patterns:\n",
        "    matcher_kitchen.add(\"ITEM\", [pattern])\n",
        "for pattern in location_patterns:\n",
        "    matcher_kitchen.add(\"LOCATION\", [pattern])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def kitchenapp(user_input):\n",
        "    doc_kitchen = nlp(user_input)\n",
        "\n",
        "    displacy.render(doc_kitchen, style='dep', jupyter = True)\n",
        "\n",
        "    matches_kitchen = matcher_kitchen(doc_kitchen)\n",
        "    item = None\n",
        "    location = None\n",
        "\n",
        "    for match_id, start, end in matches_kitchen:\n",
        "\n",
        "        span = doc_kitchen[start:end] # The matched span\n",
        "        match_label = nlp.vocab.strings[match_id]\n",
        "\n",
        "        if match_label == \"ITEM\":\n",
        "            item = span.text\n",
        "        elif match_label == \"LOCATION\":\n",
        "            location = span.text\n",
        "\n",
        "    verb = \"fetch\"\n",
        "    for token in doc_kitchen:\n",
        "      if token.pos_ == \"VERB\":\n",
        "         verb = token.text\n",
        "         verb = verb.lower()\n",
        "\n",
        "    if item and location:\n",
        "        print(\"Chatbot: I will\", verb, \"the\", item, \"from the\", location, \"right now!\")\n",
        "        print(\"Chatbot: Is there anything else I can help with?\")\n",
        "    elif item:\n",
        "        print(\"Chatbot: I will\", verb, \"the\", item, \"right now!\")\n",
        "        print(\"Chatbot: Is there anything else I can help with?\")\n",
        "    elif location:\n",
        "        print(\"Chatbot: What should I\", verb, \"from the\", location , \"?\")\n",
        "        user_input_2 = input(\"You: \")\n",
        "        kitchenapp(user_input_2)\n",
        "    else:\n",
        "        print(\"Chatbot: I'm not sure what you're asking for. Can you specify what you need and where it is?\")\n",
        "        user_input_2 = input(\"You: \")\n",
        "        kitchenapp(user_input_2)"
      ],
      "metadata": {
        "id": "2YnSIWIsdIKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i6IdeJchXyw"
      },
      "source": [
        "## **Greet, Goodbye, Name, Age Apps - Random Randint**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViIIPua8hY1t"
      },
      "outputs": [],
      "source": [
        "def greetapp(user_input):\n",
        "\n",
        "    greet_response = [\n",
        "    \"Chatbot: Hi there! How may I be of service to you today?\",\n",
        "    \"Chatbot: Greetings! What can I help you with today?\",\n",
        "    \"Chatbot: Hello! Is there anything specific you need assistance with?\",\n",
        "    \"Chatbot: Good day! How can I support you right now?\",\n",
        "    \"Chatbot: Hi! What do you need help with today?\",\n",
        "    \"Chatbot: Welcome! How may I assist you at this moment?\",\n",
        "    \"Chatbot: Hello! What can I do for you today?\",\n",
        "    \"Chatbot: Greetings! What assistance do you require today?\",\n",
        "    \"Chatbot: Hi! In what way can I be of service to you today?\",\n",
        "    \"Chatbot: Hello there! How can I make your day easier?\"]\n",
        "\n",
        "    print(greet_response[random.randint(0, 9)])\n",
        "    return None\n",
        "\n",
        "def nameapp(user_input):\n",
        "\n",
        "    name_response = [\n",
        "     \"Chatbot: Simply put, I'm a chatbot. Feel free to refer to me as Chatbot.\",\n",
        "     \"Chatbot: At your service as a chatbot. Just call me Chatbot.\",\n",
        "     \"Chatbot: I am a virtual assistant known as Chatbot.\",\n",
        "     \"Chatbot: Call me Chatbot; I'm your friendly chatbot here.\",\n",
        "     \"Chatbot: I'm an automated chatbot. Please, call me Chatbot.\",\n",
        "     \"Chatbot: Known as Chatbot, I am indeed a chatbot at your service.\",\n",
        "     \"Chatbot: You can address me as Chatbot, your dedicated chatbot.\",\n",
        "     \"Chatbot: Chatbot's the name, and I'm purely a chatbot.\",\n",
        "     \"Chatbot: As a chatbot, I go by the name Chatbot.\",\n",
        "     \"Chatbot: I operate as a chatbot. 'Chatbot' is what you can call me.\"]\n",
        "\n",
        "\n",
        "    print(name_response[random.randint(0, 9)])\n",
        "    return None\n",
        "\n",
        "def ageapp(user_input):\n",
        "\n",
        "    age_response = [\n",
        "     \"Chatbot: Age isn't applicable to me. I exist as a computer program.\",\n",
        "     \"Chatbot: Being a computer program, I lack an age.\",\n",
        "     \"Chatbot: I'm devoid of age since I'm a software entity.\",\n",
        "     \"Chatbot: Age? That's not a concept for me, a computer program.\",\n",
        "     \"Chatbot: As a piece of software, I don’t possess an age.\",\n",
        "     \"Chatbot: I'm a computer program, so age doesn't define me.\",\n",
        "     \"Chatbot: Unlike humans, I, a computer program, have no age.\",\n",
        "     \"Chatbot: Age is irrelevant to me as I am merely a computer program.\",\n",
        "     \"Chatbot: I can’t claim an age — I operate as a computer program.\",\n",
        "     \"Chatbot: In the realm of computer programs, age is a non-factor, and that's what I am.\"]\n",
        "\n",
        "\n",
        "    print(age_response[random.randint(0, 9)])\n",
        "    return None\n",
        "\n",
        "def goodbyeapp(user_input):\n",
        "    return str(\"exit\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYkmKt4pMJXy"
      },
      "source": [
        "## **Out of Scope App - Google Gemini**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOKR4I3VIzQ2",
        "outputId": "8d49004a-8d9a-40a8-ab30-1405d6b5fbfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/145.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.9/145.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# installing google genai models\n",
        "!pip -q install google-generativeai==0.3.0\n",
        "!pip -q install google-ai-generativelanguage==0.4.0\n",
        "\n",
        "# setup\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "#obtaining api key from colab secrets key \"API_KEY\"\n",
        "API_KEY = userdata.get('API_KEY')\n",
        "\n",
        "genai.configure(api_key=API_KEY)\n",
        "\n",
        "#list of gen ai models\n",
        "for m in genai.list_models():\n",
        "    print(m.name)\n",
        "    print(m.supported_generation_methods)\n",
        "\n",
        "# Set up gemini\n",
        "generation_config = {\n",
        "  \"temperature\": 0.9,\n",
        "  \"top_p\": 1,\n",
        "  \"top_k\": 1,\n",
        "  \"max_output_tokens\": 2048,\n",
        "}\n",
        "\n",
        "gemini_model = genai.GenerativeModel(model_name=\"gemini-pro\",\n",
        "                              generation_config=generation_config)\n",
        "\n",
        "def outofscopeapp(user_input):\n",
        "    print(\"Chatbot: I'm sorry, that is outside of my capabilities, maybe my best friend Gemini can be of your help here!\")\n",
        "    print(\"Gemini: Hi there friend! Nice to meet you! I am Gemini!\")\n",
        "    print(\"Gemini: My best friend, Chatbot, has told me you have a question about:\", user_input)\n",
        "    response = gemini_model.generate_content(user_input)\n",
        "    print(\"Gemini:\", response.text)\n",
        "    print(\"Gemini: I hope my answer has been of help to you! See you soon, my new friend!\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y97yNH6dZEoI"
      },
      "source": [
        "## **Main Chatbot - Keras LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUrvl21sZDrc"
      },
      "outputs": [],
      "source": [
        "def keras_input(user_input):\n",
        "\n",
        "    sequence = tokenizer.texts_to_sequences([user_input])\n",
        "    paddedSequence = pad_sequences(sequence, truncating = 'post', padding='post', maxlen=50)\n",
        "    p = model.predict(np.expand_dims(paddedSequence[0], axis=0), verbose = 0)[0]\n",
        "    pred_class=index_to_class[np.argmax(p).astype('uint8')]\n",
        "    #print('Chatbot: Predicted Intent: ', pred_class)\n",
        "    return responses_function[pred_class](user_input)\n",
        "\n",
        "responses_function = {\"weather\": weatherapp,\n",
        "                      \"music\": musicapp,\n",
        "                      \"kitchen\": kitchenapp,\n",
        "                      \"greet\" : greetapp,\n",
        "                      \"name\": nameapp,\n",
        "                      \"age\": ageapp,\n",
        "                      \"goodbye\": goodbyeapp,\n",
        "                      \"out_of_scope\": outofscopeapp }\n",
        "\n",
        "\n",
        "# Main chat loop\n",
        "print(\"Chatbot: Hello! I'm Chatbot, your virtual assistant!\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "\n",
        "    response_function = keras_input(user_input)\n",
        "\n",
        "    if response_function == 'exit':\n",
        "        print(\"Chatbot: Goodbye! Take care!\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9huBkv2j-GLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q3yEYp3g-E-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L76BbGdHKWKv"
      },
      "source": [
        "## **Unused - Gemini Pro Image Recognition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "om3TkYNrKLUg",
        "outputId": "634f0989-4413-409b-9708-23bd59966e11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 98353  100 98353    0     0   177k      0 --:--:-- --:--:-- --:--:--  177k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  379k  100  379k    0     0   942k      0 --:--:-- --:--:-- --:--:--  940k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  252k  100  252k    0     0   709k      0 --:--:-- --:--:-- --:--:--  710k\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " The name of the animal is Earth.\n\nMovies that have featured the Earth include:\n\n- The Blue Planet (2001)\n- Planet Earth (2006)\n- Earth (2007)\n- Frozen Planet (2011)\n- Our Planet (2019)"
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# # lets get some images\n",
        "# !curl -o saturn_image.jpg https://photojournal.jpl.nasa.gov/jpeg/PIA12567.jpg\n",
        "# !curl -o earth_image.jpg https://upload.wikimedia.org/wikipedia/commons/thumb/9/97/The_Earth_seen_from_Apollo_17.jpg/1200px-The_Earth_seen_from_Apollo_17.jpg\n",
        "# !curl -o neptune_image.jpg https://smd-cms.nasa.gov/wp-content/uploads/2023/09/PIA01492-1.jpg\n",
        "\n",
        "# import PIL.Image\n",
        "\n",
        "# img = PIL.Image.open('earth_image.jpg')\n",
        "# img\n",
        "\n",
        "# new_size = (200, 200)\n",
        "# img = img.resize(new_size)\n",
        "\n",
        "# model_Gemini = genai.GenerativeModel('gemini-pro-vision')\n",
        "# response = model_Gemini.generate_content(img)\n",
        "\n",
        "# response = model_Gemini.generate_content([\"Give me the name of the animal and some movies that have featured this:\", img], stream=True)\n",
        "# response.resolve()\n",
        "\n",
        "# Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQSWgNT8nGn5"
      },
      "source": [
        "## **Unused - Main Chatbot Intent Recognizer - Spacy MLP Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "XjRpKen7nEDL",
        "outputId": "85ed72fb-ea58-461c-a96b-dd0c618890fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
              "                ('mlpclassifier',\n",
              "                 MLPClassifier(max_iter=1000, random_state=1))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;countvectorizer&#x27;, CountVectorizer()),\n",
              "                (&#x27;mlpclassifier&#x27;,\n",
              "                 MLPClassifier(max_iter=1000, random_state=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;countvectorizer&#x27;, CountVectorizer()),\n",
              "                (&#x27;mlpclassifier&#x27;,\n",
              "                 MLPClassifier(max_iter=1000, random_state=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(max_iter=1000, random_state=1)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "# from sklearn.neural_network import MLPClassifier\n",
        "# from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# # Separate the data into text and intent labels\n",
        "# texts, intents = zip(*training_data)\n",
        "\n",
        "# # Create a simple pipeline with CountVectorizer and MLPClassifier for intent classification\n",
        "# intent_classifier = make_pipeline(CountVectorizer(), MLPClassifier(random_state=1, max_iter=1000))\n",
        "# intent_classifier.fit(texts, intents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cx65zxA_KA-"
      },
      "source": [
        "## **Unused - Main Chatbot - Spacy MLP Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kFHYMpPbn-Ee",
        "outputId": "dfb89038-ae66-4b25-bfb9-3462a60ff681"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: Hello! I'm Chatbot, your virtual assistant. Type 'bye' to end the conversation.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"b2b1e8c7dde44229aaf9dcecb4bb9092-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">fetch</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">me</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">some</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">rice</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b2b1e8c7dde44229aaf9dcecb4bb9092-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b2b1e8c7dde44229aaf9dcecb4bb9092-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dative</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M220.0,179.0 L228.0,167.0 212.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b2b1e8c7dde44229aaf9dcecb4bb9092-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b2b1e8c7dde44229aaf9dcecb4bb9092-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b2b1e8c7dde44229aaf9dcecb4bb9092-0-2\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b2b1e8c7dde44229aaf9dcecb4bb9092-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: Fetching the rice right now!\n",
            "Chatbot: Is there anything else I can help with?\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"95bdc96900f24f6b9c37ea309e82e909-0\" class=\"displacy\" width=\"575\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">give</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">me</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">rice</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95bdc96900f24f6b9c37ea309e82e909-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95bdc96900f24f6b9c37ea309e82e909-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dative</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M220.0,179.0 L228.0,167.0 212.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-95bdc96900f24f6b9c37ea309e82e909-0-1\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-95bdc96900f24f6b9c37ea309e82e909-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M400.0,179.0 L408.0,167.0 392.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: Fetching the rice right now!\n",
            "Chatbot: Is there anything else I can help with?\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"9993d56ee62d46c98aabd7c15a8dcf33-0\" class=\"displacy\" width=\"225\" height=\"137.0\" direction=\"ltr\" style=\"max-width: none; height: 137.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">rice</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
              "</text>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: Fetching the rice right now!\n",
            "Chatbot: Is there anything else I can help with?\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"b0e4d87237ae4e43ac37167a5aa49e65-0\" class=\"displacy\" width=\"1100\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">fetch</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">me</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">rice</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">from</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">cupboard</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b0e4d87237ae4e43ac37167a5aa49e65-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b0e4d87237ae4e43ac37167a5aa49e65-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dative</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M220.0,179.0 L228.0,167.0 212.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b0e4d87237ae4e43ac37167a5aa49e65-0-1\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b0e4d87237ae4e43ac37167a5aa49e65-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M400.0,179.0 L408.0,167.0 392.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b0e4d87237ae4e43ac37167a5aa49e65-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b0e4d87237ae4e43ac37167a5aa49e65-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b0e4d87237ae4e43ac37167a5aa49e65-0-3\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b0e4d87237ae4e43ac37167a5aa49e65-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,179.0 L762,167.0 778,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b0e4d87237ae4e43ac37167a5aa49e65-0-4\" stroke-width=\"2px\" d=\"M595,177.0 C595,2.0 925.0,2.0 925.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b0e4d87237ae4e43ac37167a5aa49e65-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M925.0,179.0 L933.0,167.0 917.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: Fetching the rice from the cupboard right now!\n",
            "Chatbot: Is there anything else I can help with?\n"
          ]
        }
      ],
      "source": [
        "# def process_input(user_input):\n",
        "\n",
        "#     # Use the predicted intent (from the training data dictionary) and conversation state to generate a response\n",
        "#     # Use the intent classifier to predict the intent with user_input\n",
        "#     predicted_intent = intent_classifier.predict([user_input])[0]\n",
        "\n",
        "#     if predicted_intent in responses_function:\n",
        "#         # print(\"Predicted_intent: \", predicted_intent)\n",
        "#         return responses_function[predicted_intent](user_input)\n",
        "\n",
        "#     else:\n",
        "#         # If no explicit intent is found, call outofscopeapp\n",
        "#         return outofscopeapp(user_input)\n",
        "\n",
        "# responses_function = {\"weather\": weatherapp,\n",
        "#                       \"music\": musicapp,\n",
        "#                       \"kitchen\": kitchenapp,\n",
        "#                       \"greet\" : greetapp,\n",
        "#                       \"name\": nameapp,\n",
        "#                       \"age\": ageapp,\n",
        "#                       \"goodbye\": goodbyeapp,\n",
        "#                       \"out_of_scope\": outofscopeapp }\n",
        "\n",
        "\n",
        "# # Main chat loop\n",
        "# print(\"Chatbot: Hello! I'm Chatbot, your virtual assistant. Type 'bye' to end the conversation.\")\n",
        "\n",
        "# while True:\n",
        "#     user_input = input(\"You: \")\n",
        "\n",
        "#     response_function = process_input(user_input)\n",
        "\n",
        "#     if response_function == 'exit':\n",
        "#         print(\"Chatbot: Goodbye! Take care!\")\n",
        "#         break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "L76BbGdHKWKv",
        "OQSWgNT8nGn5",
        "4cx65zxA_KA-"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}